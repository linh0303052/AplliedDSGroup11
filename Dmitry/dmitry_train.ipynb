{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d74719ef",
   "metadata": {},
   "source": [
    "# Import thư viện và tải dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18db85bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Normalizer, PolynomialFeatures, MinMaxScaler\n",
    "from datetime import date\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import glob\n",
    "import sys, getopt, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02442e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-01-07 20:03:39--  https://github.com/linh0303052/AplliedDSGroup11/raw/main/data.tar.gz\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/linh0303052/AplliedDSGroup11/main/data.tar.gz [following]\n",
      "--2022-01-07 20:03:39--  https://raw.githubusercontent.com/linh0303052/AplliedDSGroup11/main/data.tar.gz\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12633830 (12M) [application/octet-stream]\n",
      "Saving to: ‘data.tar.gz’\n",
      "\n",
      "data.tar.gz         100%[===================>]  12.05M  8.57MB/s    in 1.4s    \n",
      "\n",
      "2022-01-07 20:03:40 (8.57 MB/s) - ‘data.tar.gz’ saved [12633830/12633830]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/linh0303052/AplliedDSGroup11/raw/main/data.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be18c238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/\n",
      "data/input/\n",
      "data/input/5fold_20times.csv\n",
      "data/input/sample_submission.csv\n",
      "data/input/test.csv\n",
      "data/input/train.csv\n",
      "data/output/\n",
      "data/output/features/\n",
      "data/output/features/dmitry_pca_feats.csv\n",
      "data/output/features/kmeans_feats.csv\n",
      "data/output/features/tsne_feats.csv\n"
     ]
    }
   ],
   "source": [
    "!tar -xzvf data.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e37055",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/input/train.csv')\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85502c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./data/input/test.csv')\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5331726",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = './data/input/'\n",
    "OUTPUT_PATH = './data/output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8510fe",
   "metadata": {},
   "source": [
    "# Tiền xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cffbab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xử lý các giá trị đặc biệt, thay thế nó bằng giá trị NA (-999.0)\n",
    "def process_base(train, test):\n",
    "    train.loc[(train['var38']>117310.979) & (train['var38']<117310.98), 'var38'] = -999.0\n",
    "    test.loc[(test['var38']>117310.979) & (test['var38']<117310.98), 'var38'] = -999.0\n",
    "\n",
    "    train.loc[train['var3']==-999999, 'var3'] = -999.0\n",
    "    test.loc[test['var3']==-999999, 'var3'] = -999.0\n",
    "\n",
    "    for f in ['imp_op_var40_comer_ult1', 'imp_op_var40_efect_ult3', 'imp_op_var41_comer_ult3', 'imp_sal_var16_ult1']:\n",
    "        train.loc[train[f]==0.0, f] = -999.0\n",
    "        test.loc[test[f]==0.0, f] = -999.0\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b6013f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_sparse(train, test):\n",
    "    flist = [x for x in train.columns if not x in ['ID','TARGET']]\n",
    "    for f in flist:\n",
    "        if len(np.unique(train[f]))<2:\n",
    "            train.drop(f, axis=1, inplace=True)\n",
    "            test.drop(f, axis=1, inplace=True)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12640965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicated(train, test):    \n",
    "    #Loại bỏ var6 vì nó trùng với var29\n",
    "    flist = [x for x in train.columns if not x in ['ID','TARGET']]            \n",
    "    train.drop([x for x in flist if 'var6' in x], axis=1, inplace=True)\n",
    "    test.drop([x for x in flist if 'var6' in x], axis=1, inplace=True)\n",
    "\n",
    "    #Loại bỏ các thuộc tính có chứa _0 vì nó bị trùng với cột có chứa _1 theo ngay sau\n",
    "    flist = [x for x in train.columns if not x in ['ID','TARGET']]        \n",
    "    flist_remove = []\n",
    "    for i in range(len(flist)-1):\n",
    "        v = train[flist[i]].values\n",
    "        for j in range(i+1, len(flist)):\n",
    "            if np.array_equal(v, train[flist[j]].values):\n",
    "                if '_0' in flist[j]:\n",
    "                    flist_remove.append(flist[j])\n",
    "                elif  '_0' in flist[i]:\n",
    "                    flist_remove.append(flist[i])\n",
    "    train.drop(flist_remove, axis=1, inplace=True)\n",
    "    test.drop(flist_remove, axis=1, inplace=True)\n",
    "\n",
    "    #Loại bỏ các cột bị trùng khác\n",
    "    flist_remove = ['saldo_medio_var13_medio_ult1', 'delta_imp_reemb_var13_1y3', 'delta_imp_reemb_var17_1y3', \n",
    "                       'delta_imp_reemb_var33_1y3', 'delta_imp_trasp_var17_in_1y3', 'delta_imp_trasp_var17_out_1y3',\n",
    "                       'delta_imp_trasp_var33_in_1y3', 'delta_imp_trasp_var33_out_1y3']\n",
    "    train.drop(flist_remove, axis=1, inplace=True)\n",
    "    test.drop(flist_remove, axis=1, inplace=True)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a24edbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chuẩn hóa các giá trị thuộc tính\n",
    "def normalize_features(train, test):\n",
    "    flist = [x for x in train.columns if not x in ['ID','TARGET']]\n",
    "    for f in flist:\n",
    "        if train[f].max() == 9999999999.0:\n",
    "            fmax = train.loc[train[f]<9999999999.0, f].max()\n",
    "            train.loc[train[f]==9999999999.0, f] = fmax + 1\n",
    "\n",
    "        if len(train.loc[train[f]<0, f].value_counts()) == 1:\n",
    "            train.loc[train[f]<0, f] = -1.0\n",
    "            test.loc[test[f]<0, f] = -1.0\n",
    "            fmax = max(np.max(train[f]), np.max(test[f]))\n",
    "            if fmax > 0:\n",
    "                train.loc[train[f]>0, f] = 1.0*train.loc[train[f]>0, f]/fmax\n",
    "                test.loc[test[f]>0, f] = 1.0*test.loc[test[f]>0, f]/fmax\n",
    "\n",
    "        if len(train.loc[train[f]<0, f]) == 0:\n",
    "            fmax = max(np.max(train[f]), np.max(test[f]))\n",
    "            if fmax > 0:\n",
    "                train.loc[train[f]>0, f] = 1.0*train.loc[train[f]>0, f]/fmax\n",
    "                test.loc[test[f]>0, f] = 1.0*test.loc[test[f]>0, f]/fmax\n",
    "\n",
    "        if len(train.loc[train[f]<0, f].value_counts()) > 1:\n",
    "            fmax = max(np.max(train[f]), np.max(test[f]))\n",
    "            if fmax > 0:\n",
    "                train[f] = 1.0*train[f]/fmax\n",
    "                test[f] = 1.0*test[f]/fmax\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a85719",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b918d496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#thuộc tính t_SNE\n",
    "np.random.seed(12324)\n",
    "train_tsne, test_tsne = add_features(train, test, ['SumZeros'])\n",
    "\n",
    "flist = [x for x in train_tsne.columns if not x in ['ID','TARGET']]\n",
    "\n",
    "X = train_tsne[flist].append(test_tsne[flist], ignore_index=True).values.astype('float64')\n",
    "svd = TruncatedSVD(n_components=30)\n",
    "X_svd = svd.fit_transform(X)\n",
    "X_scaled = StandardScaler().fit_transform(X_svd)\n",
    "feats_tsne = TSNE(n_components=2, random_state=0).fit_transform(X_scaled)\n",
    "feats_tsne = pd.DataFrame(feats_tsne, columns=['tsne1', 'tsne2'])\n",
    "feats_tsne['ID'] = train_tsne[['ID']].append(test_tsne[['ID']], ignore_index=True)['ID'].values\n",
    "train_tsne = pd.merge(train_tsne, feats_tsne, on='ID', how='left')\n",
    "test_tsne = pd.merge(test_tsne, feats_tsne, on='ID', how='left')\n",
    "\n",
    "feat = train_tsne[['ID', 'tsne1', 'tsne2']].append(test_tsne[['ID', 'tsne1', 'tsne2']], ignore_index=True)\n",
    "feat.to_csv(OUTPUT_PATH + 'tsne_feats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c534d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#thuộc tính PCA\n",
    "train_pca, test_pca = add_features(train, test, ['SumZeros'])\n",
    "\n",
    "flist = [x for x in train_pca.columns if not x in ['ID','TARGET']]\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "x_train_projected = pca.fit_transform(normalize(train_pca[flist], axis=0))\n",
    "x_test_projected = pca.transform(normalize(test_pca[flist], axis=0))\n",
    "train_pca.insert(1, 'PCAOne', x_train_projected[:, 0])\n",
    "train_pca.insert(1, 'PCATwo', x_train_projected[:, 1])\n",
    "test_pca.insert(1, 'PCAOne', x_test_projected[:, 0])\n",
    "test_pca.insert(1, 'PCATwo', x_test_projected[:, 1])\n",
    "pca_feats = train_pca[['ID', 'PCAOne', 'PCATwo']].append(test_pca[['ID', 'PCAOne', 'PCATwo']], ignore_index=True)\n",
    "pca_feats.to_csv(OUTPUT_PATH + 'dmitry_pca_feats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0597df4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#thuộc tính k-means\n",
    "train_k, test_k = add_features(train, test, ['SumZeros'])\n",
    "train_k, test_k = normalize_features(train_k, test_k)\n",
    "\n",
    "flist = [x for x in train_k.columns if not x in ['ID','TARGET']]\n",
    "\n",
    "flist_kmeans = []\n",
    "for ncl in range(2,11):\n",
    "    cls = KMeans(n_clusters=ncl)\n",
    "    cls.fit_predict(train_k[flist].values)\n",
    "    train_k['kmeans_cluster'+str(ncl)] = cls.predict(train_k[flist].values)\n",
    "    test_k['kmeans_cluster'+str(ncl)] = cls.predict(test_k[flist].values)\n",
    "    flist_kmeans.append('kmeans_cluster'+str(ncl))\n",
    "\n",
    "train[['ID']+flist_kmeans].append(test[['ID']+flist_kmeans], ignore_index=True).to_csv(OUTPUT_PATH + 'kmeans_feats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4770e292",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
