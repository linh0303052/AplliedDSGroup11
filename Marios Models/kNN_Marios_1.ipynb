{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a44cda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from collections import defaultdict\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "868b3f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadcolumn(filename,col=4, skip=1, floats=True):\n",
    "    pred=[]\n",
    "    op=open(filename,'r')\n",
    "    if skip==1:\n",
    "        op.readline() #header\n",
    "    for line in op:\n",
    "        line=line.replace('\\n','')\n",
    "        sps=line.split(',')\n",
    "        #load always the last columns\n",
    "        if floats:\n",
    "            pred.append(float(sps[col]))\n",
    "        else :\n",
    "            pred.append(str(sps[col]))\n",
    "    op.close()\n",
    "    return np.array(pred)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c438d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datas(filename):\n",
    "\n",
    "    return joblib.load(filename)\n",
    "\n",
    "def printfile(X, filename):\n",
    "\n",
    "    joblib.dump((X), filename)\n",
    "    \n",
    "def printfilcsve(X, filename, headers):\n",
    "\n",
    "    np.savetxt(filename,X, header=headers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16f1a01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ids(id_file, cols=20):\n",
    "    verybiglist=[]\n",
    "    for s in range(0,cols):\n",
    "        idss=loadcolumn(id_file,col=s, skip=1, floats=True)\n",
    "        id_list=[ [] ,[] , [], [] , []]\n",
    "        id_dict=[ defaultdict(int) ,defaultdict(int) , defaultdict(int), defaultdict(int) , defaultdict(int)]\n",
    "        for g in range(0,len(idss)):\n",
    "            id_list[int(idss[g])].append(g)\n",
    "            id_dict[int(idss[g])][g]=1\n",
    "        biglist=[]\n",
    "        for k in range(5):\n",
    "            training_ids=[s for s in range(0,len(idss)) if s not in id_dict[k] ]\n",
    "            biglist.append([training_ids,id_list[k] ])\n",
    "            print(len(biglist), len(biglist[0]))\n",
    "        verybiglist.append(biglist)\n",
    "            \n",
    "    return verybiglist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d4e1dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_load_vecorizerr(tr,te,drop=[\"ind_var2_0\",\"ind_var2\",\"ind_var27_0\",\"ind_var28_0\",\"ind_var28\",\"ind_var27\",\n",
    "\"ind_var41\",\"ind_var46_0\",\"ind_var46\",\"num_var27_0\",\"num_var28_0\",\"num_var28\",\"num_var27\",\"num_var41\",\"num_var46_0\",\n",
    "\"num_var46\",\"saldo_var28\",\"saldo_var27\",\"saldo_var41\",\"saldo_var46\",\"imp_amort_var18_hace3\",\"imp_amort_var34_hace3\",\n",
    "\"imp_reemb_var13_hace3\",\"imp_reemb_var33_hace3\",\"imp_trasp_var17_out_hace3\",\"imp_trasp_var33_out_hace3\",\n",
    "\"num_var2_0_ult1\",\"num_var2_ult1\",\"num_reemb_var13_hace3\",\"num_reemb_var33_hace3\",\"num_trasp_var17_out_hace3\",\n",
    "\"num_trasp_var33_out_hace3\",\"saldo_var2_ult1\",\"saldo_medio_var13_medio_hace3\",\"ind_var6_0\",\"ind_var6\",\n",
    "\"ind_var13_medio_0\",\"ind_var18_0\",\"ind_var26_0\",\"ind_var25_0\",\"ind_var32_0\",\"ind_var34_0\",\"ind_var37_0\",\n",
    "\"ind_var40\",\"num_var6_0\",\"num_var6\",\"num_var13_medio_0\",\"num_var18_0\",\"num_var26_0\",\"num_var25_0\",\"num_var32_0\",\n",
    "\"num_var34_0\",\"num_var37_0\",\"num_var40\",\"saldo_var6\",\"saldo_var13_medio\",\"delta_imp_reemb_var13_1y3\",\n",
    "\"delta_imp_reemb_var17_1y3\",\"delta_imp_reemb_var33_1y3\",\"delta_imp_trasp_var17_in_1y3\",\"delta_imp_trasp_var17_out_1y3\",\n",
    "\"delta_imp_trasp_var33_in_1y3\",\"delta_imp_trasp_var33_out_1y3\"]):\n",
    "\n",
    "    train  = pd.read_csv(tr, sep=',',quotechar='\"')\n",
    "    test  = pd.read_csv(te, sep=',',quotechar='\"')\n",
    "    train.drop('ID', axis=1, inplace=True)\n",
    "    train.drop('TARGET', axis=1, inplace=True)    \n",
    "    test.drop('ID', axis=1, inplace=True)\n",
    "    for name in drop:\n",
    "        train.drop(name, axis=1, inplace=True)    \n",
    "        test.drop(name, axis=1, inplace=True)        \n",
    "\n",
    "    train['zerocount'] = train.apply(lambda x: np.sum(x == 0), axis=1)\n",
    "    test['zerocount'] = test.apply(lambda x: np.sum(x == 0), axis=1)\n",
    "\n",
    "    train['var38'].replace(117310.979016494, -1.0, inplace=True)\n",
    "    test ['var38'].replace(117310.979016494, -1.0, inplace=True)\n",
    "    \n",
    "    train_s = train\n",
    "    test_s = test\n",
    "    result = pd.concat([test_s,train_s])\n",
    "    \n",
    "    #test_s.drop('id', axis=1, inplace=True)\n",
    "    result=result.T.to_dict().values()\n",
    "    train = train_s.T.to_dict().values()\n",
    "    test = test_s.T.to_dict().values()\n",
    "    \n",
    "    vec = DictVectorizer()\n",
    "    vec.fit(result)\n",
    "    train = vec.transform(train)\n",
    "    test = vec.transform(test)\n",
    "    \n",
    "    print(train.shape)\n",
    "    print(test.shape)\n",
    "    \n",
    "    \n",
    "    return train,test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e40da21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagged_set(X_t,y_c,model, seed, estimators, xt, update_seed=True):\n",
    "    \n",
    "   # create array object to hold predictions \n",
    "   baggedpred=[ 0.0  for d in range(0, (xt.shape[0]))]\n",
    "   #loop for as many times as we want bags\n",
    "   for n in range (0, estimators):\n",
    "        #shuff;e first, aids in increasing variance and forces different results\n",
    "        #X_t,y_c=shuffle(Xs,ys, random_state=seed+n)\n",
    "          \n",
    "        if update_seed: # update seed if requested, to give a slightly different model\n",
    "            model.set_params(random_state=seed + n)\n",
    "        model.fit(X_t,y_c) # fit model0.0917411475506\n",
    "        preds=model.predict_proba(xt)[:,1] # predict probabilities\n",
    "        # update bag's array\n",
    "        for j in range (0, (xt.shape[0])):           \n",
    "                baggedpred[j]+=preds[j]\n",
    "        #print(\"done bag %d mean %f  \" % (n,meanthis))\n",
    "   # divide with number of bags to create an average estimate            \n",
    "   for j in range (0, len(baggedpred)): \n",
    "                baggedpred[j]/=float(estimators)\n",
    "   # return probabilities            \n",
    "   return np.array(baggedpred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5ff8c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-059bc691594b>:33: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  result=result.T.to_dict().values()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76020, 307)\n",
      "(75818, 307)\n",
      "(76020, 2)\n",
      "(75818, 2)\n",
      "(76020, 309)\n",
      "(75818, 309)\n",
      "kfolder\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "starting cross validation with 5 kfolds \n",
      "folder 0  train size: 60790. test size: 15230, cols: 309 \n",
      "folder 0 size train: 60790 size cv: 15230 AUC (fold 1/5): 0.791626\n",
      "folder 0  train size: 60879. test size: 15141, cols: 309 \n",
      "folder 0 size train: 60879 size cv: 15141 AUC (fold 2/5): 0.796849\n",
      "folder 0  train size: 60739. test size: 15281, cols: 309 \n",
      "folder 0 size train: 60739 size cv: 15281 AUC (fold 3/5): 0.800872\n",
      "folder 0  train size: 60752. test size: 15268, cols: 309 \n",
      "folder 0 size train: 60752 size cv: 15268 AUC (fold 4/5): 0.783397\n",
      "folder 0  train size: 60920. test size: 15100, cols: 309 \n",
      "folder 0 size train: 60920 size cv: 15100 AUC (fold 5/5): 0.807926\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 1  train size: 60869. test size: 15151, cols: 309 \n",
      "folder 1 size train: 60869 size cv: 15151 AUC (fold 1/5): 0.795001\n",
      "folder 1  train size: 60833. test size: 15187, cols: 309 \n",
      "folder 1 size train: 60833 size cv: 15187 AUC (fold 2/5): 0.801761\n",
      "folder 1  train size: 60700. test size: 15320, cols: 309 \n",
      "folder 1 size train: 60700 size cv: 15320 AUC (fold 3/5): 0.811127\n",
      "folder 1  train size: 60955. test size: 15065, cols: 309 \n",
      "folder 1 size train: 60955 size cv: 15065 AUC (fold 4/5): 0.782508\n",
      "folder 1  train size: 60723. test size: 15297, cols: 309 \n",
      "folder 1 size train: 60723 size cv: 15297 AUC (fold 5/5): 0.793155\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 2  train size: 60746. test size: 15274, cols: 309 \n",
      "folder 2 size train: 60746 size cv: 15274 AUC (fold 1/5): 0.814925\n",
      "folder 2  train size: 60710. test size: 15310, cols: 309 \n",
      "folder 2 size train: 60710 size cv: 15310 AUC (fold 2/5): 0.783965\n",
      "folder 2  train size: 61055. test size: 14965, cols: 309 \n",
      "folder 2 size train: 61055 size cv: 14965 AUC (fold 3/5): 0.802216\n",
      "folder 2  train size: 60788. test size: 15232, cols: 309 \n",
      "folder 2 size train: 60788 size cv: 15232 AUC (fold 4/5): 0.806173\n",
      "folder 2  train size: 60781. test size: 15239, cols: 309 \n",
      "folder 2 size train: 60781 size cv: 15239 AUC (fold 5/5): 0.776082\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 3  train size: 60889. test size: 15131, cols: 309 \n",
      "folder 3 size train: 60889 size cv: 15131 AUC (fold 1/5): 0.799328\n",
      "folder 3  train size: 60822. test size: 15198, cols: 309 \n",
      "folder 3 size train: 60822 size cv: 15198 AUC (fold 2/5): 0.789308\n",
      "folder 3  train size: 60695. test size: 15325, cols: 309 \n",
      "folder 3 size train: 60695 size cv: 15325 AUC (fold 3/5): 0.793865\n",
      "folder 3  train size: 60830. test size: 15190, cols: 309 \n",
      "folder 3 size train: 60830 size cv: 15190 AUC (fold 4/5): 0.795617\n",
      "folder 3  train size: 60844. test size: 15176, cols: 309 \n",
      "folder 3 size train: 60844 size cv: 15176 AUC (fold 5/5): 0.802787\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 4  train size: 60749. test size: 15271, cols: 309 \n",
      "folder 4 size train: 60749 size cv: 15271 AUC (fold 1/5): 0.786587\n",
      "folder 4  train size: 60899. test size: 15121, cols: 309 \n",
      "folder 4 size train: 60899 size cv: 15121 AUC (fold 2/5): 0.802725\n",
      "folder 4  train size: 60942. test size: 15078, cols: 309 \n",
      "folder 4 size train: 60942 size cv: 15078 AUC (fold 3/5): 0.787810\n",
      "folder 4  train size: 60729. test size: 15291, cols: 309 \n",
      "folder 4 size train: 60729 size cv: 15291 AUC (fold 4/5): 0.807038\n",
      "folder 4  train size: 60761. test size: 15259, cols: 309 \n",
      "folder 4 size train: 60761 size cv: 15259 AUC (fold 5/5): 0.797092\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 5  train size: 60817. test size: 15203, cols: 309 \n",
      "folder 5 size train: 60817 size cv: 15203 AUC (fold 1/5): 0.800429\n",
      "folder 5  train size: 60811. test size: 15209, cols: 309 \n",
      "folder 5 size train: 60811 size cv: 15209 AUC (fold 2/5): 0.796649\n",
      "folder 5  train size: 60951. test size: 15069, cols: 309 \n",
      "folder 5 size train: 60951 size cv: 15069 AUC (fold 3/5): 0.797477\n",
      "folder 5  train size: 60798. test size: 15222, cols: 309 \n",
      "folder 5 size train: 60798 size cv: 15222 AUC (fold 4/5): 0.796537\n",
      "folder 5  train size: 60703. test size: 15317, cols: 309 \n",
      "folder 5 size train: 60703 size cv: 15317 AUC (fold 5/5): 0.790959\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 6  train size: 60903. test size: 15117, cols: 309 \n",
      "folder 6 size train: 60903 size cv: 15117 AUC (fold 1/5): 0.805424\n",
      "folder 6  train size: 60774. test size: 15246, cols: 309 \n",
      "folder 6 size train: 60774 size cv: 15246 AUC (fold 2/5): 0.797137\n",
      "folder 6  train size: 60666. test size: 15354, cols: 309 \n",
      "folder 6 size train: 60666 size cv: 15354 AUC (fold 3/5): 0.791861\n",
      "folder 6  train size: 60880. test size: 15140, cols: 309 \n",
      "folder 6 size train: 60880 size cv: 15140 AUC (fold 4/5): 0.801092\n",
      "folder 6  train size: 60857. test size: 15163, cols: 309 \n",
      "folder 6 size train: 60857 size cv: 15163 AUC (fold 5/5): 0.789963\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 7  train size: 60817. test size: 15203, cols: 309 \n",
      "folder 7 size train: 60817 size cv: 15203 AUC (fold 1/5): 0.797840\n",
      "folder 7  train size: 60868. test size: 15152, cols: 309 \n",
      "folder 7 size train: 60868 size cv: 15152 AUC (fold 2/5): 0.792471\n",
      "folder 7  train size: 60733. test size: 15287, cols: 309 \n",
      "folder 7 size train: 60733 size cv: 15287 AUC (fold 3/5): 0.770262\n",
      "folder 7  train size: 61062. test size: 14958, cols: 309 \n",
      "folder 7 size train: 61062 size cv: 14958 AUC (fold 4/5): 0.801569\n",
      "folder 7  train size: 60600. test size: 15420, cols: 309 \n",
      "folder 7 size train: 60600 size cv: 15420 AUC (fold 5/5): 0.816681\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 8  train size: 60771. test size: 15249, cols: 309 \n",
      "folder 8 size train: 60771 size cv: 15249 AUC (fold 1/5): 0.791860\n",
      "folder 8  train size: 60731. test size: 15289, cols: 309 \n",
      "folder 8 size train: 60731 size cv: 15289 AUC (fold 2/5): 0.797480\n",
      "folder 8  train size: 60927. test size: 15093, cols: 309 \n",
      "folder 8 size train: 60927 size cv: 15093 AUC (fold 3/5): 0.793874\n",
      "folder 8  train size: 60818. test size: 15202, cols: 309 \n",
      "folder 8 size train: 60818 size cv: 15202 AUC (fold 4/5): 0.803646\n",
      "folder 8  train size: 60833. test size: 15187, cols: 309 \n",
      "folder 8 size train: 60833 size cv: 15187 AUC (fold 5/5): 0.792304\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 9  train size: 60927. test size: 15093, cols: 309 \n",
      "folder 9 size train: 60927 size cv: 15093 AUC (fold 1/5): 0.790306\n",
      "folder 9  train size: 60836. test size: 15184, cols: 309 \n",
      "folder 9 size train: 60836 size cv: 15184 AUC (fold 2/5): 0.805279\n",
      "folder 9  train size: 60659. test size: 15361, cols: 309 \n",
      "folder 9 size train: 60659 size cv: 15361 AUC (fold 3/5): 0.771708\n",
      "folder 9  train size: 60873. test size: 15147, cols: 309 \n",
      "folder 9 size train: 60873 size cv: 15147 AUC (fold 4/5): 0.794115\n",
      "folder 9  train size: 60785. test size: 15235, cols: 309 \n",
      "folder 9 size train: 60785 size cv: 15235 AUC (fold 5/5): 0.807677\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 10  train size: 60695. test size: 15325, cols: 309 \n",
      "folder 10 size train: 60695 size cv: 15325 AUC (fold 1/5): 0.802878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder 10  train size: 60800. test size: 15220, cols: 309 \n",
      "folder 10 size train: 60800 size cv: 15220 AUC (fold 2/5): 0.807847\n",
      "folder 10  train size: 60806. test size: 15214, cols: 309 \n",
      "folder 10 size train: 60806 size cv: 15214 AUC (fold 3/5): 0.795949\n",
      "folder 10  train size: 60594. test size: 15426, cols: 309 \n",
      "folder 10 size train: 60594 size cv: 15426 AUC (fold 4/5): 0.790000\n",
      "folder 10  train size: 61185. test size: 14835, cols: 309 \n",
      "folder 10 size train: 61185 size cv: 14835 AUC (fold 5/5): 0.782961\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 11  train size: 60697. test size: 15323, cols: 309 \n",
      "folder 11 size train: 60697 size cv: 15323 AUC (fold 1/5): 0.782399\n",
      "folder 11  train size: 60929. test size: 15091, cols: 309 \n",
      "folder 11 size train: 60929 size cv: 15091 AUC (fold 2/5): 0.804316\n",
      "folder 11  train size: 60806. test size: 15214, cols: 309 \n",
      "folder 11 size train: 60806 size cv: 15214 AUC (fold 3/5): 0.807242\n",
      "folder 11  train size: 60904. test size: 15116, cols: 309 \n",
      "folder 11 size train: 60904 size cv: 15116 AUC (fold 4/5): 0.803214\n",
      "folder 11  train size: 60744. test size: 15276, cols: 309 \n",
      "folder 11 size train: 60744 size cv: 15276 AUC (fold 5/5): 0.781722\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 12  train size: 60707. test size: 15313, cols: 309 \n",
      "folder 12 size train: 60707 size cv: 15313 AUC (fold 1/5): 0.806963\n",
      "folder 12  train size: 60752. test size: 15268, cols: 309 \n",
      "folder 12 size train: 60752 size cv: 15268 AUC (fold 2/5): 0.786875\n",
      "folder 12  train size: 60916. test size: 15104, cols: 309 \n",
      "folder 12 size train: 60916 size cv: 15104 AUC (fold 3/5): 0.779775\n",
      "folder 12  train size: 60806. test size: 15214, cols: 309 \n",
      "folder 12 size train: 60806 size cv: 15214 AUC (fold 4/5): 0.792501\n",
      "folder 12  train size: 60899. test size: 15121, cols: 309 \n",
      "folder 12 size train: 60899 size cv: 15121 AUC (fold 5/5): 0.807124\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 13  train size: 60821. test size: 15199, cols: 309 \n",
      "folder 13 size train: 60821 size cv: 15199 AUC (fold 1/5): 0.779689\n",
      "folder 13  train size: 60994. test size: 15026, cols: 309 \n",
      "folder 13 size train: 60994 size cv: 15026 AUC (fold 2/5): 0.803689\n",
      "folder 13  train size: 60788. test size: 15232, cols: 309 \n",
      "folder 13 size train: 60788 size cv: 15232 AUC (fold 3/5): 0.799588\n",
      "folder 13  train size: 60676. test size: 15344, cols: 309 \n",
      "folder 13 size train: 60676 size cv: 15344 AUC (fold 4/5): 0.796135\n",
      "folder 13  train size: 60801. test size: 15219, cols: 309 \n",
      "folder 13 size train: 60801 size cv: 15219 AUC (fold 5/5): 0.803006\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 14  train size: 60941. test size: 15079, cols: 309 \n",
      "folder 14 size train: 60941 size cv: 15079 AUC (fold 1/5): 0.801769\n",
      "folder 14  train size: 60631. test size: 15389, cols: 309 \n",
      "folder 14 size train: 60631 size cv: 15389 AUC (fold 2/5): 0.801068\n",
      "folder 14  train size: 60718. test size: 15302, cols: 309 \n",
      "folder 14 size train: 60718 size cv: 15302 AUC (fold 3/5): 0.793168\n",
      "folder 14  train size: 60897. test size: 15123, cols: 309 \n",
      "folder 14 size train: 60897 size cv: 15123 AUC (fold 4/5): 0.790740\n",
      "folder 14  train size: 60893. test size: 15127, cols: 309 \n",
      "folder 14 size train: 60893 size cv: 15127 AUC (fold 5/5): 0.792280\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 15  train size: 60754. test size: 15266, cols: 309 \n",
      "folder 15 size train: 60754 size cv: 15266 AUC (fold 1/5): 0.810319\n",
      "folder 15  train size: 60813. test size: 15207, cols: 309 \n",
      "folder 15 size train: 60813 size cv: 15207 AUC (fold 2/5): 0.796841\n",
      "folder 15  train size: 60955. test size: 15065, cols: 309 \n",
      "folder 15 size train: 60955 size cv: 15065 AUC (fold 3/5): 0.785629\n",
      "folder 15  train size: 60704. test size: 15316, cols: 309 \n",
      "folder 15 size train: 60704 size cv: 15316 AUC (fold 4/5): 0.795918\n",
      "folder 15  train size: 60854. test size: 15166, cols: 309 \n",
      "folder 15 size train: 60854 size cv: 15166 AUC (fold 5/5): 0.786979\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 16  train size: 60876. test size: 15144, cols: 309 \n",
      "folder 16 size train: 60876 size cv: 15144 AUC (fold 1/5): 0.793168\n",
      "folder 16  train size: 60785. test size: 15235, cols: 309 \n",
      "folder 16 size train: 60785 size cv: 15235 AUC (fold 2/5): 0.780203\n",
      "folder 16  train size: 60817. test size: 15203, cols: 309 \n",
      "folder 16 size train: 60817 size cv: 15203 AUC (fold 3/5): 0.806527\n",
      "folder 16  train size: 60911. test size: 15109, cols: 309 \n",
      "folder 16 size train: 60911 size cv: 15109 AUC (fold 4/5): 0.801858\n",
      "folder 16  train size: 60691. test size: 15329, cols: 309 \n",
      "folder 16 size train: 60691 size cv: 15329 AUC (fold 5/5): 0.799070\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 17  train size: 60996. test size: 15024, cols: 309 \n",
      "folder 17 size train: 60996 size cv: 15024 AUC (fold 1/5): 0.793477\n",
      "folder 17  train size: 60808. test size: 15212, cols: 309 \n",
      "folder 17 size train: 60808 size cv: 15212 AUC (fold 2/5): 0.805825\n",
      "folder 17  train size: 60770. test size: 15250, cols: 309 \n",
      "folder 17 size train: 60770 size cv: 15250 AUC (fold 3/5): 0.800438\n",
      "folder 17  train size: 60767. test size: 15253, cols: 309 \n",
      "folder 17 size train: 60767 size cv: 15253 AUC (fold 4/5): 0.783284\n",
      "folder 17  train size: 60739. test size: 15281, cols: 309 \n",
      "folder 17 size train: 60739 size cv: 15281 AUC (fold 5/5): 0.791372\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 18  train size: 60781. test size: 15239, cols: 309 \n",
      "folder 18 size train: 60781 size cv: 15239 AUC (fold 1/5): 0.790655\n",
      "folder 18  train size: 60992. test size: 15028, cols: 309 \n",
      "folder 18 size train: 60992 size cv: 15028 AUC (fold 2/5): 0.792407\n",
      "folder 18  train size: 60814. test size: 15206, cols: 309 \n",
      "folder 18 size train: 60814 size cv: 15206 AUC (fold 3/5): 0.808184\n",
      "folder 18  train size: 60679. test size: 15341, cols: 309 \n",
      "folder 18 size train: 60679 size cv: 15341 AUC (fold 4/5): 0.803982\n",
      "folder 18  train size: 60814. test size: 15206, cols: 309 \n",
      "folder 18 size train: 60814 size cv: 15206 AUC (fold 5/5): 0.789933\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 19  train size: 60774. test size: 15246, cols: 309 \n",
      "folder 19 size train: 60774 size cv: 15246 AUC (fold 1/5): 0.790701\n",
      "folder 19  train size: 60653. test size: 15367, cols: 309 \n",
      "folder 19 size train: 60653 size cv: 15367 AUC (fold 2/5): 0.786438\n",
      "folder 19  train size: 60863. test size: 15157, cols: 309 \n",
      "folder 19 size train: 60863 size cv: 15157 AUC (fold 3/5): 0.811947\n",
      "folder 19  train size: 60897. test size: 15123, cols: 309 \n",
      "folder 19 size train: 60897 size cv: 15123 AUC (fold 4/5): 0.788950\n",
      "folder 19  train size: 60893. test size: 15127, cols: 309 \n",
      "folder 19 size train: 60893 size cv: 15127 AUC (fold 5/5): 0.805095\n",
      "==============================================================================================\n",
      " Grand AUC: 0.797451\n",
      " printing train datasets \n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/output/train/knn_marios_1.train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-4525ad534253>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0mmean_kapa\u001b[0m\u001b[1;33m/=\u001b[0m\u001b[0mnumber_of_folds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" printing train datasets \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m     \u001b[0mprintfilcsve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midstrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_stacker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetafolder_train\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0moutset\u001b[0m  \u001b[1;33m+\u001b[0m \u001b[1;34m\".train.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"ID,TARGET\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[0mstda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-452a35d8cadb>\u001b[0m in \u001b[0;36mprintfilcsve\u001b[1;34m(X, filename, headers)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprintfilcsve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msavetxt\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msavetxt\u001b[1;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;31m# datasource doesn't support creating a new file ...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1366\u001b[1;33m         \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1367\u001b[0m         \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1368\u001b[0m         \u001b[0mown_fh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/output/train/knn_marios_1.train.csv'"
     ]
    }
   ],
   "source": [
    "load_data=True\n",
    "metafolder_train=\"../data/output/train/\" \n",
    "metafolder_test=\"../data/output/test/\"        \n",
    "input_folder=\"../data/input/\"\n",
    "feature_folder=\"../data/output/features/\"\n",
    "\n",
    "SEED=15\n",
    "outset=\"knn_marios_1\" # predic of all files\n",
    "number_of_folds=5 # repeat the CV procedure 10 times to get more precise results       \n",
    "\n",
    "######### Load files ############\n",
    "\n",
    "y=loadcolumn(input_folder+ \"train.csv\",col=370, skip=1, floats=True)\n",
    "ids=loadcolumn(input_folder+ \"test.csv\",col=0, skip=1, floats=True)\n",
    "idstrain=loadcolumn(input_folder+ \"train.csv\",col=0, skip=1, floats=True)\n",
    "keepfold=[0 for k in range(len(y))]\n",
    "\n",
    "if load_data:\n",
    "    X,X_test=all_load_vecorizerr(input_folder+'train.csv',input_folder+'test.csv') \n",
    "    printfile(X,\"Xvector.pkl\")  \n",
    "    printfile(X_test,\"Xtestvector.pkl\")                               \n",
    "    X=load_datas(\"Xvector.pkl\").toarray()\n",
    "    X_test=load_datas(\"Xtestvector.pkl\").toarray()\n",
    "\n",
    "\n",
    "tsn_features=(np.loadtxt(feature_folder+ 'tsne_feats.csv', delimiter=\",\", skiprows=1, usecols=(1,2)))\n",
    "\n",
    "tsn_features_train=tsn_features[:X.shape[0]]\n",
    "tsn_features_test=tsn_features[X.shape[0]:tsn_features.shape[0]]     \n",
    "\n",
    "print(tsn_features_train.shape)\n",
    "print(tsn_features_test.shape)\n",
    "\n",
    "X=np.column_stack((X,tsn_features_train))     \n",
    "X_test=np.column_stack((X_test,tsn_features_test)) \n",
    "\n",
    "print(X.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "#model to use\n",
    "                \n",
    "model=KNeighborsClassifier(n_neighbors=500,weights='uniform',algorithm='brute',metric='cityblock',n_jobs=30)  \n",
    "\n",
    "#Create Arrays for meta\n",
    "train_stacker=[ 0.0  for k in range (0,(X.shape[0])) ]\n",
    "test_stacker=[0.0  for k in range (0,(X_test.shape[0]))]\n",
    "\n",
    "# CHECK EVerything in five..it could be more efficient     \n",
    "\n",
    "#create target variable        \n",
    "print(\"kfolder\")\n",
    "\n",
    "#load the 20-fold ids.\n",
    "kfolders=load_ids(input_folder+\"5fold_20times.csv\")  \n",
    "\n",
    "printfile(kfolders,\"kfolder.pkl\")                   \n",
    "kfolders=load_datas(\"kfolder.pkl\")\n",
    "\n",
    "fcount=0\n",
    "#number_of_folds=0\n",
    "#X,y=shuffle(X,y, random_state=SEED) # Shuffle since the data is ordered by time\n",
    "for kfolder in kfolders:\n",
    "    mean_kapa = 0.0\n",
    "    i=0 # iterator counter\n",
    "    print (\"starting cross validation with %d kfolds \" % (number_of_folds))\n",
    "    if number_of_folds>0:\n",
    "        for train_index, test_index in kfolder:\n",
    "            # creaning and validation sets\n",
    "            X_train, X_cv = X[train_index], X[test_index]\n",
    "            y_train, y_cv = np.array(y)[train_index], np.array(y)[test_index]\n",
    "\n",
    "            stda=StandardScaler()            \n",
    "            X_train=stda.fit_transform(X_train)\n",
    "            X_cv=stda.transform(X_cv)                            \n",
    "            print (\"folder %d  train size: %d. test size: %d, cols: %d \" % (fcount, (X_train.shape[0]) ,(X_cv.shape[0]) ,(X_train.shape[1]) ))\n",
    "\n",
    "            \n",
    "            preds=bagged_set(X_train,y_train,model, SEED, 1, X_cv, update_seed=False)\n",
    "          \n",
    "            # compute Loglikelihood metric for this CV fold\n",
    "            #scalepreds(preds)     \n",
    "            kapa = roc_auc_score(y_cv,preds)\n",
    "            print(\"folder %d size train: %d size cv: %d AUC (fold %d/%d): %f\" % (fcount,(X_train.shape[0]), (X_cv.shape[0]), i + 1, number_of_folds, kapa))\n",
    "            mean_kapa += kapa\n",
    "            #save the results\n",
    "            no=0\n",
    "            for real_index in test_index:\n",
    "                      train_stacker[real_index]+=(preds[no])\n",
    "                      keepfold[real_index]=i\n",
    "                      no+=1\n",
    "            i+=1\n",
    "    fcount+=1\n",
    "    print(\"==============================================================================================\")\n",
    "for u in range(0,len(train_stacker)):\n",
    "    train_stacker[u]/=float(len(kfolders))\n",
    "grand_auc=roc_auc_score(y, train_stacker)\n",
    "print (\" Grand AUC: %f\" % (grand_auc) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88af81fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " printing train datasets \n",
      " making test predictions \n"
     ]
    }
   ],
   "source": [
    "if (number_of_folds)>0:\n",
    "    mean_kapa/=number_of_folds\n",
    "    print (\" printing train datasets \")\n",
    "    printfilcsve(np.column_stack((np.array(idstrain),np.array(train_stacker))), metafolder_train+ outset  + \".train.csv\",\"ID,TARGET\")  \n",
    "\n",
    "stda=StandardScaler()            \n",
    "X=stda.fit_transform(X)\n",
    "X_test=stda.transform(X_test)        \n",
    "\n",
    "print (\" making test predictions \")        \n",
    "preds=bagged_set(X, y,model, SEED, 1, X_test, update_seed=False) \n",
    "  \n",
    "for pr in range (0,len(preds)):            \n",
    "            test_stacker[pr]=(preds[pr]) \n",
    "\n",
    "preds=np.array(preds)\n",
    "printfilcsve(np.column_stack((np.array(ids),np.array(test_stacker))),  metafolder_test+ outset  + \".test.csv\",\"ID,TARGET\")                \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
