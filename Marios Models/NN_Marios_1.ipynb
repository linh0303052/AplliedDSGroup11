{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/linh0303052/AplliedDSGroup11/blob/main/Marios%20Models/NN_Marios_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TvLxe5iOzmf5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16666/1740452500.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvanced_activations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPReLU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from collections import defaultdict\n",
    "import tensorflow as tf\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.regularizers import *\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "D8EJld1P3oj8"
   },
   "outputs": [],
   "source": [
    "epc=100\n",
    "batch=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YZVF00Uv3pA0"
   },
   "outputs": [],
   "source": [
    "def build_model(input_dim, output_dim):\n",
    "    models = Sequential()\n",
    "\n",
    "    models.add(Dense(120, input_dim=input_dim, kernel_regularizer=l2(0.00001)))\n",
    "    models.add(PReLU())\n",
    "    models.add(BatchNormalization())\n",
    "    models.add(Dropout(0.6))\n",
    "    models.add(Dense(output_dim))\n",
    "    models.add(Activation('softmax'))\n",
    "\n",
    "    opt = tf.keras.optimizers.Adagrad(learning_rate=0.0125)\n",
    "    models.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return models\n",
    "\n",
    "def loadcolumn(filename,col=4, skip=1, floats=True):\n",
    "    pred=[]\n",
    "    op=open(filename,'r')\n",
    "    if skip==1:\n",
    "        op.readline() #header\n",
    "    for line in op:\n",
    "        line=line.replace('\\n','')\n",
    "        sps=line.split(',')\n",
    "        #load always the last columns\n",
    "        if floats:\n",
    "            pred.append(float(sps[col]))\n",
    "        else :\n",
    "            pred.append(str(sps[col]))\n",
    "    op.close()\n",
    "    return np.array(pred)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xrkpAiNC3vTz"
   },
   "outputs": [],
   "source": [
    "def load_datas(filename):\n",
    "\n",
    "    return joblib.load(filename)\n",
    "\n",
    "def printfile(X, filename):\n",
    "\n",
    "    joblib.dump((X), filename)\n",
    "    \n",
    "def printfilcsve(X, filename, headers):\n",
    "\n",
    "    np.savetxt(filename,X, header=headers) \n",
    "\n",
    "    \n",
    "    \n",
    "def load_ids(id_file, cols=20):\n",
    "    verybiglist=[]\n",
    "    for s in range(0,cols):\n",
    "        idss=loadcolumn(id_file,col=s, skip=1, floats=True)\n",
    "        id_list=[ [] ,[] , [], [] , []]\n",
    "        id_dict=[ defaultdict(int) ,defaultdict(int) , defaultdict(int), defaultdict(int) , defaultdict(int)]\n",
    "        for g in range(0,len(idss)):\n",
    "            id_list[int(idss[g])].append(g)\n",
    "            id_dict[int(idss[g])][g]=1\n",
    "        biglist=[]\n",
    "        for k in range(5):\n",
    "            training_ids=[s for s in range(0,len(idss)) if s not in id_dict[k] ]\n",
    "            biglist.append([training_ids,id_list[k] ])\n",
    "            print(len(biglist), len(biglist[0]))\n",
    "        verybiglist.append(biglist)\n",
    "            \n",
    "    return verybiglist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-eXOFJdY3zS7"
   },
   "outputs": [],
   "source": [
    "def all_load_vecorizerr(tr,te,drop=[\"ind_var2_0\",\"ind_var2\",\"ind_var27_0\",\"ind_var28_0\",\"ind_var28\",\"ind_var27\",\n",
    "\"ind_var41\",\"ind_var46_0\",\"ind_var46\",\"num_var27_0\",\"num_var28_0\",\"num_var28\",\"num_var27\",\"num_var41\",\"num_var46_0\",\n",
    "\"num_var46\",\"saldo_var28\",\"saldo_var27\",\"saldo_var41\",\"saldo_var46\",\"imp_amort_var18_hace3\",\"imp_amort_var34_hace3\",\n",
    "\"imp_reemb_var13_hace3\",\"imp_reemb_var33_hace3\",\"imp_trasp_var17_out_hace3\",\"imp_trasp_var33_out_hace3\",\n",
    "\"num_var2_0_ult1\",\"num_var2_ult1\",\"num_reemb_var13_hace3\",\"num_reemb_var33_hace3\",\"num_trasp_var17_out_hace3\",\n",
    "\"num_trasp_var33_out_hace3\",\"saldo_var2_ult1\",\"saldo_medio_var13_medio_hace3\",\"ind_var6_0\",\"ind_var6\",\n",
    "\"ind_var13_medio_0\",\"ind_var18_0\",\"ind_var26_0\",\"ind_var25_0\",\"ind_var32_0\",\"ind_var34_0\",\"ind_var37_0\",\n",
    "\"ind_var40\",\"num_var6_0\",\"num_var6\",\"num_var13_medio_0\",\"num_var18_0\",\"num_var26_0\",\"num_var25_0\",\"num_var32_0\",\n",
    "\"num_var34_0\",\"num_var37_0\",\"num_var40\",\"saldo_var6\",\"saldo_var13_medio\",\"delta_imp_reemb_var13_1y3\",\n",
    "\"delta_imp_reemb_var17_1y3\",\"delta_imp_reemb_var33_1y3\",\"delta_imp_trasp_var17_in_1y3\",\"delta_imp_trasp_var17_out_1y3\",\n",
    "\"delta_imp_trasp_var33_in_1y3\",\"delta_imp_trasp_var33_out_1y3\"]):\n",
    "\n",
    "    train  = pd.read_csv(tr, sep=',',quotechar='\"')\n",
    "    test  = pd.read_csv(te, sep=',',quotechar='\"')\n",
    "    train.drop('ID', axis=1, inplace=True)\n",
    "    train.drop('TARGET', axis=1, inplace=True)    \n",
    "    test.drop('ID', axis=1, inplace=True)\n",
    "    for name in drop:\n",
    "        train.drop(name, axis=1, inplace=True)    \n",
    "        test.drop(name, axis=1, inplace=True)        \n",
    "\n",
    "    train['zerocount'] = train.apply(lambda x: np.sum(x == 0), axis=1)\n",
    "    test['zerocount'] = test.apply(lambda x: np.sum(x == 0), axis=1)\n",
    "\n",
    "    train['var38'].replace(117310.979016494, -1.0, inplace=True)\n",
    "    test ['var38'].replace(117310.979016494, -1.0, inplace=True)\n",
    "    \n",
    "    train_s = train\n",
    "    test_s = test\n",
    "    result = pd.concat([test_s,train_s])\n",
    "    \n",
    "    #test_s.drop('id', axis=1, inplace=True)\n",
    "    result=result.T.to_dict().values()\n",
    "    train = train_s.T.to_dict().values()\n",
    "    test = test_s.T.to_dict().values()\n",
    "    \n",
    "    vec = DictVectorizer()\n",
    "    vec.fit(result)\n",
    "    train = vec.transform(train)\n",
    "    test = vec.transform(test)\n",
    "    \n",
    "    print(train.shape)\n",
    "    print(test.shape)  \n",
    "    \n",
    "    \n",
    "    return train,test\n",
    "\n",
    "def bagged_set(X,y, seed, estimators, xt, nval=0.0, verbos=0): \n",
    "  \n",
    "   baggedpred=[ 0.0 for d in range(0, xt.shape[0])] \n",
    "           \n",
    "   for i in range (0, estimators): \n",
    "        \n",
    "        X_t,y_c=shuffle(X,y, random_state=seed+i) \n",
    "        np.random.seed(seed+i)\n",
    "        model = build_model(xt.shape[1], 2)\n",
    "        if nval>0.0:\n",
    "            x_train_oof, x_valid_oof, y_train_oof_nn, y_valid_oof_nn = cross_validation.train_test_split(\n",
    "            X_t, y_c, test_size=nval, random_state=i*seed)\n",
    "            model.fit(x_train_oof,np_utils.to_categorical( y_train_oof_nn),\n",
    "                      epochs=epc, batch_size=batch,\n",
    "                      validation_data=(x_valid_oof,np_utils.to_categorical(y_valid_oof_nn)), \n",
    "                    verbose=verbos, callbacks=[MonitorAUC(x_valid_oof,y_valid_oof_nn)])\n",
    "        else :\n",
    "            y_train_oof_nn = np_utils.to_categorical(y_c)\n",
    "            model.fit(X_t, y_train_oof_nn, epochs=epc, batch_size=batch, verbose=verbos)\n",
    "\n",
    "         \n",
    "        preds =model.predict(xt) [:,1]\n",
    " \n",
    "        for j in range (0, xt.shape[0]):            \n",
    "                 baggedpred[j]+=preds[j] \n",
    "        #print(\"finshed bag %d\" % (i+1)) \n",
    "                \n",
    "   for j in range (0, len(baggedpred)):         \n",
    "                baggedpred[j]/=float(estimators) \n",
    "                \n",
    "   return np.array(baggedpred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "XIuS7NFE32yD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-ddce7e6b46c8>:33: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  result=result.T.to_dict().values()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76020, 307)\n",
      "(75818, 307)\n",
      "(76020, 2)\n",
      "(75818, 2)\n",
      "(76020, 309)\n",
      "(75818, 309)\n",
      "(76020, 2)\n",
      "(75818, 2)\n",
      "(76020, 311)\n",
      "(75818, 311)\n",
      "kfolder\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n"
     ]
    }
   ],
   "source": [
    "load_data=True      \n",
    "metafolder_train=\"../data/output/train/\" \n",
    "metafolder_test=\"../data/output/test/\"        \n",
    "input_folder=\"../data/input/\"\n",
    "feature_folder=\"../data/output/features/\"\n",
    "SEED=15\n",
    "outset=\"nn_marios_1\" # predic of all files\n",
    "number_of_folds=5 # repeat the CV procedure 10 times to get more precise results       \n",
    "\n",
    "######### Load files ############\n",
    "\n",
    "y=loadcolumn(input_folder+ \"train.csv\",col=370, skip=1, floats=True)\n",
    "ids=loadcolumn(input_folder+ \"test.csv\",col=0, skip=1, floats=True)\n",
    "idstrain=loadcolumn(input_folder+ \"train.csv\",col=0, skip=1, floats=True)\n",
    "keepfold=[0 for k in range(len(y))]\n",
    "\n",
    "if load_data:\n",
    "    X,X_test=all_load_vecorizerr(input_folder+'train.csv',input_folder+'test.csv') \n",
    "    printfile(X,\"Xvector.pkl\")  \n",
    "    printfile(X_test,\"Xtestvector.pkl\")                               \n",
    "    X=load_datas(\"Xvector.pkl\").toarray()\n",
    "    X_test=load_datas(\"Xtestvector.pkl\").toarray()\n",
    "\n",
    "\n",
    "tsn_features=(np.loadtxt(feature_folder+ \"tsne_feats.csv\", delimiter=\",\", skiprows=1, usecols=[1,2]))\n",
    "\n",
    "tsn_features_train=tsn_features[:X.shape[0]]\n",
    "tsn_features_test=tsn_features[X.shape[0]:tsn_features.shape[0]]     \n",
    "\n",
    "print(tsn_features_train.shape)\n",
    "print(tsn_features_test.shape)\n",
    "\n",
    "X=np.column_stack((X,tsn_features_train))     \n",
    "X_test=np.column_stack((X_test,tsn_features_test)) \n",
    "\n",
    "print(X.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "pca_features=(np.loadtxt(feature_folder+\"dmitry_pca_feats.csv\", delimiter=\",\", skiprows=1, usecols=[1,2]))\n",
    "\n",
    "dmitry_pca_feats_train=pca_features[:X.shape[0]]\n",
    "dmitry_pca_feats_test=pca_features[X.shape[0]:pca_features.shape[0]]     \n",
    "\n",
    "print(dmitry_pca_feats_train.shape)\n",
    "print(dmitry_pca_feats_test.shape)\n",
    "\n",
    "X=np.column_stack((X,dmitry_pca_feats_train))     \n",
    "X_test=np.column_stack((X_test,dmitry_pca_feats_test)) \n",
    "\n",
    "print(X.shape)     \n",
    "print(X_test.shape)\n",
    "\n",
    "\n",
    "#Create Arrays for meta\n",
    "train_stacker=[ 0.0  for k in range (0,(X.shape[0])) ]\n",
    "test_stacker=[0.0  for k in range (0,(X_test.shape[0]))]\n",
    "\n",
    "# CHECK EVerything in five..it could be more efficient     \n",
    "\n",
    "#create target variable        \n",
    "\n",
    "#kfolder=StratifiedKFold(y, n_folds=number_of_folds,shuffle=True, random_state=SEED)\n",
    "print(\"kfolder\")\n",
    "\n",
    "#load the 20-fold ids.        \n",
    "kfolders=load_ids(input_folder+\"5fold_20times.csv\")  \n",
    "\n",
    "printfile(kfolders,\"kfolder.pkl\")                   \n",
    "kfolders=load_datas(\"kfolder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting cross validation with 5 kfolds \n",
      "folder 0  train size: 60790. test size: 15230, cols: 311 \n",
      "folder 0 size train: 60790 size cv: 15230 AUC (fold 1/5): 0.810364\n",
      "folder 0  train size: 60879. test size: 15141, cols: 311 \n",
      "folder 0 size train: 60879 size cv: 15141 AUC (fold 2/5): 0.812554\n",
      "folder 0  train size: 60739. test size: 15281, cols: 311 \n",
      "folder 0 size train: 60739 size cv: 15281 AUC (fold 3/5): 0.816589\n",
      "folder 0  train size: 60752. test size: 15268, cols: 311 \n",
      "folder 0 size train: 60752 size cv: 15268 AUC (fold 4/5): 0.807250\n",
      "folder 0  train size: 60920. test size: 15100, cols: 311 \n",
      "folder 0 size train: 60920 size cv: 15100 AUC (fold 5/5): 0.829792\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 1  train size: 60869. test size: 15151, cols: 311 \n",
      "folder 1 size train: 60869 size cv: 15151 AUC (fold 1/5): 0.822339\n",
      "folder 1  train size: 60833. test size: 15187, cols: 311 \n",
      "folder 1 size train: 60833 size cv: 15187 AUC (fold 2/5): 0.816039\n",
      "folder 1  train size: 60700. test size: 15320, cols: 311 \n",
      "folder 1 size train: 60700 size cv: 15320 AUC (fold 3/5): 0.821615\n",
      "folder 1  train size: 60955. test size: 15065, cols: 311 \n",
      "folder 1 size train: 60955 size cv: 15065 AUC (fold 4/5): 0.811142\n",
      "folder 1  train size: 60723. test size: 15297, cols: 311 \n",
      "folder 1 size train: 60723 size cv: 15297 AUC (fold 5/5): 0.814975\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 2  train size: 60746. test size: 15274, cols: 311 \n",
      "folder 2 size train: 60746 size cv: 15274 AUC (fold 1/5): 0.825319\n",
      "folder 2  train size: 60710. test size: 15310, cols: 311 \n",
      "folder 2 size train: 60710 size cv: 15310 AUC (fold 2/5): 0.804411\n",
      "folder 2  train size: 61055. test size: 14965, cols: 311 \n",
      "folder 2 size train: 61055 size cv: 14965 AUC (fold 3/5): 0.823602\n",
      "folder 2  train size: 60788. test size: 15232, cols: 311 \n",
      "folder 2 size train: 60788 size cv: 15232 AUC (fold 4/5): 0.834654\n",
      "folder 2  train size: 60781. test size: 15239, cols: 311 \n",
      "folder 2 size train: 60781 size cv: 15239 AUC (fold 5/5): 0.796921\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 3  train size: 60889. test size: 15131, cols: 311 \n",
      "folder 3 size train: 60889 size cv: 15131 AUC (fold 1/5): 0.818394\n",
      "folder 3  train size: 60822. test size: 15198, cols: 311 \n",
      "folder 3 size train: 60822 size cv: 15198 AUC (fold 2/5): 0.806657\n",
      "folder 3  train size: 60695. test size: 15325, cols: 311 \n",
      "folder 3 size train: 60695 size cv: 15325 AUC (fold 3/5): 0.810760\n",
      "folder 3  train size: 60830. test size: 15190, cols: 311 \n",
      "folder 3 size train: 60830 size cv: 15190 AUC (fold 4/5): 0.820969\n",
      "folder 3  train size: 60844. test size: 15176, cols: 311 \n",
      "folder 3 size train: 60844 size cv: 15176 AUC (fold 5/5): 0.827555\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 4  train size: 60749. test size: 15271, cols: 311 \n",
      "folder 4 size train: 60749 size cv: 15271 AUC (fold 1/5): 0.806434\n",
      "folder 4  train size: 60899. test size: 15121, cols: 311 \n",
      "folder 4 size train: 60899 size cv: 15121 AUC (fold 2/5): 0.817158\n",
      "folder 4  train size: 60942. test size: 15078, cols: 311 \n",
      "folder 4 size train: 60942 size cv: 15078 AUC (fold 3/5): 0.803027\n",
      "folder 4  train size: 60729. test size: 15291, cols: 311 \n",
      "folder 4 size train: 60729 size cv: 15291 AUC (fold 4/5): 0.819392\n",
      "folder 4  train size: 60761. test size: 15259, cols: 311 \n",
      "folder 4 size train: 60761 size cv: 15259 AUC (fold 5/5): 0.829012\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 5  train size: 60817. test size: 15203, cols: 311 \n",
      "folder 5 size train: 60817 size cv: 15203 AUC (fold 1/5): 0.826251\n",
      "folder 5  train size: 60811. test size: 15209, cols: 311 \n",
      "folder 5 size train: 60811 size cv: 15209 AUC (fold 2/5): 0.822744\n",
      "folder 5  train size: 60951. test size: 15069, cols: 311 \n",
      "folder 5 size train: 60951 size cv: 15069 AUC (fold 3/5): 0.810838\n",
      "folder 5  train size: 60798. test size: 15222, cols: 311 \n",
      "folder 5 size train: 60798 size cv: 15222 AUC (fold 4/5): 0.810529\n",
      "folder 5  train size: 60703. test size: 15317, cols: 311 \n",
      "folder 5 size train: 60703 size cv: 15317 AUC (fold 5/5): 0.817635\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 6  train size: 60903. test size: 15117, cols: 311 \n",
      "folder 6 size train: 60903 size cv: 15117 AUC (fold 1/5): 0.818583\n",
      "folder 6  train size: 60774. test size: 15246, cols: 311 \n",
      "folder 6 size train: 60774 size cv: 15246 AUC (fold 2/5): 0.803809\n",
      "folder 6  train size: 60666. test size: 15354, cols: 311 \n",
      "folder 6 size train: 60666 size cv: 15354 AUC (fold 3/5): 0.826091\n",
      "folder 6  train size: 60880. test size: 15140, cols: 311 \n",
      "folder 6 size train: 60880 size cv: 15140 AUC (fold 4/5): 0.818260\n",
      "folder 6  train size: 60857. test size: 15163, cols: 311 \n",
      "folder 6 size train: 60857 size cv: 15163 AUC (fold 5/5): 0.806981\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 7  train size: 60817. test size: 15203, cols: 311 \n",
      "folder 7 size train: 60817 size cv: 15203 AUC (fold 1/5): 0.812624\n",
      "folder 7  train size: 60868. test size: 15152, cols: 311 \n",
      "folder 7 size train: 60868 size cv: 15152 AUC (fold 2/5): 0.816004\n",
      "folder 7  train size: 60733. test size: 15287, cols: 311 \n",
      "folder 7 size train: 60733 size cv: 15287 AUC (fold 3/5): 0.801351\n",
      "folder 7  train size: 61062. test size: 14958, cols: 311 \n",
      "folder 7 size train: 61062 size cv: 14958 AUC (fold 4/5): 0.818263\n",
      "folder 7  train size: 60600. test size: 15420, cols: 311 \n",
      "folder 7 size train: 60600 size cv: 15420 AUC (fold 5/5): 0.832721\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 8  train size: 60771. test size: 15249, cols: 311 \n",
      "folder 8 size train: 60771 size cv: 15249 AUC (fold 1/5): 0.812920\n",
      "folder 8  train size: 60731. test size: 15289, cols: 311 \n",
      "folder 8 size train: 60731 size cv: 15289 AUC (fold 2/5): 0.823573\n",
      "folder 8  train size: 60927. test size: 15093, cols: 311 \n",
      "folder 8 size train: 60927 size cv: 15093 AUC (fold 3/5): 0.820121\n",
      "folder 8  train size: 60818. test size: 15202, cols: 311 \n",
      "folder 8 size train: 60818 size cv: 15202 AUC (fold 4/5): 0.820088\n",
      "folder 8  train size: 60833. test size: 15187, cols: 311 \n",
      "folder 8 size train: 60833 size cv: 15187 AUC (fold 5/5): 0.799662\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 9  train size: 60927. test size: 15093, cols: 311 \n",
      "folder 9 size train: 60927 size cv: 15093 AUC (fold 1/5): 0.816991\n",
      "folder 9  train size: 60836. test size: 15184, cols: 311 \n",
      "folder 9 size train: 60836 size cv: 15184 AUC (fold 2/5): 0.820885\n",
      "folder 9  train size: 60659. test size: 15361, cols: 311 \n",
      "folder 9 size train: 60659 size cv: 15361 AUC (fold 3/5): 0.794703\n",
      "folder 9  train size: 60873. test size: 15147, cols: 311 \n",
      "folder 9 size train: 60873 size cv: 15147 AUC (fold 4/5): 0.818759\n",
      "folder 9  train size: 60785. test size: 15235, cols: 311 \n",
      "folder 9 size train: 60785 size cv: 15235 AUC (fold 5/5): 0.823755\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 10  train size: 60695. test size: 15325, cols: 311 \n",
      "folder 10 size train: 60695 size cv: 15325 AUC (fold 1/5): 0.821720\n",
      "folder 10  train size: 60800. test size: 15220, cols: 311 \n",
      "folder 10 size train: 60800 size cv: 15220 AUC (fold 2/5): 0.820393\n",
      "folder 10  train size: 60806. test size: 15214, cols: 311 \n",
      "folder 10 size train: 60806 size cv: 15214 AUC (fold 3/5): 0.821021\n",
      "folder 10  train size: 60594. test size: 15426, cols: 311 \n",
      "folder 10 size train: 60594 size cv: 15426 AUC (fold 4/5): 0.815209\n",
      "folder 10  train size: 61185. test size: 14835, cols: 311 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder 10 size train: 61185 size cv: 14835 AUC (fold 5/5): 0.803025\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 11  train size: 60697. test size: 15323, cols: 311 \n",
      "folder 11 size train: 60697 size cv: 15323 AUC (fold 1/5): 0.810713\n",
      "folder 11  train size: 60929. test size: 15091, cols: 311 \n",
      "folder 11 size train: 60929 size cv: 15091 AUC (fold 2/5): 0.823226\n",
      "folder 11  train size: 60806. test size: 15214, cols: 311 \n",
      "folder 11 size train: 60806 size cv: 15214 AUC (fold 3/5): 0.824246\n",
      "folder 11  train size: 60904. test size: 15116, cols: 311 \n",
      "folder 11 size train: 60904 size cv: 15116 AUC (fold 4/5): 0.823961\n",
      "folder 11  train size: 60744. test size: 15276, cols: 311 \n",
      "folder 11 size train: 60744 size cv: 15276 AUC (fold 5/5): 0.798716\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 12  train size: 60707. test size: 15313, cols: 311 \n",
      "folder 12 size train: 60707 size cv: 15313 AUC (fold 1/5): 0.830597\n",
      "folder 12  train size: 60752. test size: 15268, cols: 311 \n",
      "folder 12 size train: 60752 size cv: 15268 AUC (fold 2/5): 0.826510\n",
      "folder 12  train size: 60916. test size: 15104, cols: 311 \n",
      "folder 12 size train: 60916 size cv: 15104 AUC (fold 3/5): 0.800734\n",
      "folder 12  train size: 60806. test size: 15214, cols: 311 \n",
      "folder 12 size train: 60806 size cv: 15214 AUC (fold 4/5): 0.802578\n",
      "folder 12  train size: 60899. test size: 15121, cols: 311 \n",
      "folder 12 size train: 60899 size cv: 15121 AUC (fold 5/5): 0.815284\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 13  train size: 60821. test size: 15199, cols: 311 \n",
      "folder 13 size train: 60821 size cv: 15199 AUC (fold 1/5): 0.808225\n",
      "folder 13  train size: 60994. test size: 15026, cols: 311 \n",
      "folder 13 size train: 60994 size cv: 15026 AUC (fold 2/5): 0.829538\n",
      "folder 13  train size: 60788. test size: 15232, cols: 311 \n",
      "folder 13 size train: 60788 size cv: 15232 AUC (fold 3/5): 0.806361\n",
      "folder 13  train size: 60676. test size: 15344, cols: 311 \n",
      "folder 13 size train: 60676 size cv: 15344 AUC (fold 4/5): 0.815143\n",
      "folder 13  train size: 60801. test size: 15219, cols: 311 \n",
      "folder 13 size train: 60801 size cv: 15219 AUC (fold 5/5): 0.826953\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 14  train size: 60941. test size: 15079, cols: 311 \n",
      "folder 14 size train: 60941 size cv: 15079 AUC (fold 1/5): 0.815766\n",
      "folder 14  train size: 60631. test size: 15389, cols: 311 \n",
      "folder 14 size train: 60631 size cv: 15389 AUC (fold 2/5): 0.823564\n",
      "folder 14  train size: 60718. test size: 15302, cols: 311 \n",
      "folder 14 size train: 60718 size cv: 15302 AUC (fold 3/5): 0.813319\n",
      "folder 14  train size: 60897. test size: 15123, cols: 311 \n",
      "folder 14 size train: 60897 size cv: 15123 AUC (fold 4/5): 0.808636\n",
      "folder 14  train size: 60893. test size: 15127, cols: 311 \n",
      "folder 14 size train: 60893 size cv: 15127 AUC (fold 5/5): 0.811314\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 15  train size: 60754. test size: 15266, cols: 311 \n",
      "folder 15 size train: 60754 size cv: 15266 AUC (fold 1/5): 0.830926\n",
      "folder 15  train size: 60813. test size: 15207, cols: 311 \n",
      "folder 15 size train: 60813 size cv: 15207 AUC (fold 2/5): 0.808023\n",
      "folder 15  train size: 60955. test size: 15065, cols: 311 \n",
      "folder 15 size train: 60955 size cv: 15065 AUC (fold 3/5): 0.804547\n",
      "folder 15  train size: 60704. test size: 15316, cols: 311 \n",
      "folder 15 size train: 60704 size cv: 15316 AUC (fold 4/5): 0.819475\n",
      "folder 15  train size: 60854. test size: 15166, cols: 311 \n",
      "folder 15 size train: 60854 size cv: 15166 AUC (fold 5/5): 0.810169\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 16  train size: 60876. test size: 15144, cols: 311 \n",
      "folder 16 size train: 60876 size cv: 15144 AUC (fold 1/5): 0.816318\n",
      "folder 16  train size: 60785. test size: 15235, cols: 311 \n",
      "folder 16 size train: 60785 size cv: 15235 AUC (fold 2/5): 0.802027\n",
      "folder 16  train size: 60817. test size: 15203, cols: 311 \n",
      "folder 16 size train: 60817 size cv: 15203 AUC (fold 3/5): 0.830162\n",
      "folder 16  train size: 60911. test size: 15109, cols: 311 \n",
      "folder 16 size train: 60911 size cv: 15109 AUC (fold 4/5): 0.818883\n",
      "folder 16  train size: 60691. test size: 15329, cols: 311 \n",
      "folder 16 size train: 60691 size cv: 15329 AUC (fold 5/5): 0.811325\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 17  train size: 60996. test size: 15024, cols: 311 \n",
      "folder 17 size train: 60996 size cv: 15024 AUC (fold 1/5): 0.810667\n",
      "folder 17  train size: 60808. test size: 15212, cols: 311 \n",
      "folder 17 size train: 60808 size cv: 15212 AUC (fold 2/5): 0.825554\n",
      "folder 17  train size: 60770. test size: 15250, cols: 311 \n",
      "folder 17 size train: 60770 size cv: 15250 AUC (fold 3/5): 0.822548\n",
      "folder 17  train size: 60767. test size: 15253, cols: 311 \n",
      "folder 17 size train: 60767 size cv: 15253 AUC (fold 4/5): 0.807763\n",
      "folder 17  train size: 60739. test size: 15281, cols: 311 \n",
      "folder 17 size train: 60739 size cv: 15281 AUC (fold 5/5): 0.816223\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 18  train size: 60781. test size: 15239, cols: 311 \n",
      "folder 18 size train: 60781 size cv: 15239 AUC (fold 1/5): 0.806429\n",
      "folder 18  train size: 60992. test size: 15028, cols: 311 \n",
      "folder 18 size train: 60992 size cv: 15028 AUC (fold 2/5): 0.810554\n",
      "folder 18  train size: 60814. test size: 15206, cols: 311 \n",
      "folder 18 size train: 60814 size cv: 15206 AUC (fold 3/5): 0.818993\n",
      "folder 18  train size: 60679. test size: 15341, cols: 311 \n",
      "folder 18 size train: 60679 size cv: 15341 AUC (fold 4/5): 0.831774\n",
      "folder 18  train size: 60814. test size: 15206, cols: 311 \n",
      "folder 18 size train: 60814 size cv: 15206 AUC (fold 5/5): 0.807252\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 19  train size: 60774. test size: 15246, cols: 311 \n",
      "folder 19 size train: 60774 size cv: 15246 AUC (fold 1/5): 0.803562\n",
      "folder 19  train size: 60653. test size: 15367, cols: 311 \n",
      "folder 19 size train: 60653 size cv: 15367 AUC (fold 2/5): 0.810092\n",
      "folder 19  train size: 60863. test size: 15157, cols: 311 \n",
      "folder 19 size train: 60863 size cv: 15157 AUC (fold 3/5): 0.835286\n",
      "folder 19  train size: 60897. test size: 15123, cols: 311 \n",
      "folder 19 size train: 60897 size cv: 15123 AUC (fold 4/5): 0.807325\n",
      "folder 19  train size: 60893. test size: 15127, cols: 311 \n",
      "folder 19 size train: 60893 size cv: 15127 AUC (fold 5/5): 0.825330\n",
      "==============================================================================================\n",
      " Grand AUC: 0.817421\n",
      " printing train datasets \n",
      " making test predictions \n"
     ]
    }
   ],
   "source": [
    "fcount=0\n",
    "#number_of_folds=0\n",
    "#X,y=shuffle(X,y, random_state=SEED) # Shuffle since the data is ordered by time\n",
    "for kfolder in kfolders:\n",
    "    mean_kapa = 0.0\n",
    "    i=0 # iterator counter\n",
    "    print (\"starting cross validation with %d kfolds \" % (number_of_folds))\n",
    "    if number_of_folds>0:\n",
    "        for train_index, test_index in kfolder:\n",
    "            # creaning and validation sets\n",
    "            X_train, X_cv = X[train_index], X[test_index]\n",
    "            y_train, y_cv = np.array(y)[train_index], np.array(y)[test_index]\n",
    "\n",
    "            stda=StandardScaler()            \n",
    "            X_train=stda.fit_transform(X_train)\n",
    "            X_cv=stda.transform(X_cv)                    \n",
    "\n",
    "            print(\"folder %d  train size: %d. test size: %d, cols: %d \" % (fcount, (X_train.shape[0]) ,(X_cv.shape[0]) ,(X_train.shape[1]) ))\n",
    "\n",
    "            \n",
    "            preds=bagged_set(X_train,y_train, SEED, 5, X_cv)\n",
    "            \n",
    "            # compute Loglikelihood metric for this CV fold     \n",
    "            kapa = roc_auc_score(y_cv,preds)\n",
    "            print(\"folder %d size train: %d size cv: %d AUC (fold %d/%d): %f\" % (fcount,(X_train.shape[0]), (X_cv.shape[0]), i + 1, number_of_folds, kapa))\n",
    "            mean_kapa += kapa\n",
    "            #save the results\n",
    "            no=0\n",
    "            for real_index in test_index:\n",
    "                      train_stacker[real_index]+=(preds[no])\n",
    "                      keepfold[real_index]=i\n",
    "                      no+=1\n",
    "            i+=1\n",
    "    fcount+=1\n",
    "    print(\"==============================================================================================\")\n",
    "for u in range(0,len(train_stacker)):\n",
    "    train_stacker[u]/=float(len(kfolders))\n",
    "grand_auc=roc_auc_score(y, train_stacker)\n",
    "print (\" Grand AUC: %f\" % (grand_auc) )\n",
    "if (number_of_folds)>0:\n",
    "    mean_kapa/=number_of_folds\n",
    "    print (\" printing train datasets \")\n",
    "    printfilcsve(np.column_stack((np.array(idstrain),np.array(train_stacker))), metafolder_train+ outset  + \".train.csv\",\"ID,TARGET\")  \n",
    "    #printfilcsve(np.column_stack((np.array(idstrain),np.array(keepfold))),   \"id_fold.csv\",\"ID,FOLD\")\n",
    "\n",
    "#woe_train, woe_cv= convert_to_woe(np.round(X,2),y, np.round(X_test,2), seed=1, cvals=5, roundings=2, columns=None)\n",
    "\n",
    "stda=StandardScaler()            \n",
    "X=stda.fit_transform(X)\n",
    "X_test=stda.transform(X_test)           \n",
    "\n",
    "print(\" making test predictions \")        \n",
    "preds=bagged_set(X, y, SEED, 50, X_test) \n",
    "\n",
    "for pr in range (0,len(preds)):            \n",
    "            test_stacker[pr]=(preds[pr]) \n",
    "\n",
    "preds=np.array(preds)\n",
    "printfilcsve(np.column_stack((np.array(ids),np.array(test_stacker))),  metafolder_test+ outset  + \".test.csv\",\"ID,TARGET\")                "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOVvVVkyve9VXSPeCfwbnib",
   "include_colab_link": true,
   "name": "NN_Marios_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
