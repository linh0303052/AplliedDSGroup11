{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26b7bafb",
   "metadata": {
    "id": "26b7bafb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa2fbcb6",
   "metadata": {
    "id": "aa2fbcb6"
   },
   "outputs": [],
   "source": [
    "def loadcolumn(filename,col=4, skip=1, floats=True):\n",
    "    pred=[]\n",
    "    op=open(filename,'r')\n",
    "    if skip==1:\n",
    "        op.readline() #header\n",
    "    for line in op:\n",
    "        line=line.replace('\\n','')\n",
    "        sps=line.split(',')\n",
    "        #load always the last columns\n",
    "        if floats:\n",
    "            pred.append(float(sps[col]))\n",
    "        else :\n",
    "            pred.append(str(sps[col]))\n",
    "    op.close()\n",
    "    return np.array(pred)            \n",
    "\n",
    "    \n",
    "def load_datas(filename):\n",
    "\n",
    "    return joblib.load(filename)\n",
    "\n",
    "def printfile(X, filename):\n",
    "\n",
    "    joblib.dump((X), filename)\n",
    "    \n",
    "def printfilcsve(X, filename, headers):\n",
    "\n",
    "    np.savetxt(filename,X, header=headers) \n",
    "\n",
    "    \n",
    "def load_ids(id_file, cols=20):\n",
    "    verybiglist=[]\n",
    "    for s in range(0,cols):\n",
    "        idss=loadcolumn(id_file,col=s, skip=1, floats=True)\n",
    "        id_list=[ [] ,[] , [], [] , []]\n",
    "        id_dict=[ defaultdict(int) ,defaultdict(int) , defaultdict(int), defaultdict(int) , defaultdict(int)]\n",
    "        for g in range(0,len(idss)):\n",
    "            id_list[int(idss[g])].append(g)\n",
    "            id_dict[int(idss[g])][g]=1\n",
    "        biglist=[]\n",
    "        for k in range(5):\n",
    "            training_ids=[s for s in range(0,len(idss)) if s not in id_dict[k] ]\n",
    "            biglist.append([training_ids,id_list[k] ])\n",
    "            print(len(biglist), len(biglist[0]))\n",
    "        verybiglist.append(biglist)\n",
    "            \n",
    "    return verybiglist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28fb60c7",
   "metadata": {
    "id": "28fb60c7"
   },
   "outputs": [],
   "source": [
    "def all_load_vecorizerr(tr,te,drop=[\"ind_var2_0\",\"ind_var2\",\"ind_var27_0\",\"ind_var28_0\",\"ind_var28\",\"ind_var27\",\n",
    "\"ind_var41\",\"ind_var46_0\",\"ind_var46\",\"num_var27_0\",\"num_var28_0\",\"num_var28\",\"num_var27\",\"num_var41\",\"num_var46_0\",\n",
    "\"num_var46\",\"saldo_var28\",\"saldo_var27\",\"saldo_var41\",\"saldo_var46\",\"imp_amort_var18_hace3\",\"imp_amort_var34_hace3\",\n",
    "\"imp_reemb_var13_hace3\",\"imp_reemb_var33_hace3\",\"imp_trasp_var17_out_hace3\",\"imp_trasp_var33_out_hace3\",\n",
    "\"num_var2_0_ult1\",\"num_var2_ult1\",\"num_reemb_var13_hace3\",\"num_reemb_var33_hace3\",\"num_trasp_var17_out_hace3\",\n",
    "\"num_trasp_var33_out_hace3\",\"saldo_var2_ult1\",\"saldo_medio_var13_medio_hace3\",\"ind_var6_0\",\"ind_var6\",\n",
    "\"ind_var13_medio_0\",\"ind_var18_0\",\"ind_var26_0\",\"ind_var25_0\",\"ind_var32_0\",\"ind_var34_0\",\"ind_var37_0\",\n",
    "\"ind_var40\",\"num_var6_0\",\"num_var6\",\"num_var13_medio_0\",\"num_var18_0\",\"num_var26_0\",\"num_var25_0\",\"num_var32_0\",\n",
    "\"num_var34_0\",\"num_var37_0\",\"num_var40\",\"saldo_var6\",\"saldo_var13_medio\",\"delta_imp_reemb_var13_1y3\",\n",
    "\"delta_imp_reemb_var17_1y3\",\"delta_imp_reemb_var33_1y3\",\"delta_imp_trasp_var17_in_1y3\",\"delta_imp_trasp_var17_out_1y3\",\n",
    "\"delta_imp_trasp_var33_in_1y3\",\"delta_imp_trasp_var33_out_1y3\"]):\n",
    "\n",
    "    train  = pd.read_csv(tr, sep=',',quotechar='\"')\n",
    "    test  = pd.read_csv(te, sep=',',quotechar='\"')\n",
    "    train.drop('ID', axis=1, inplace=True)\n",
    "    train.drop('TARGET', axis=1, inplace=True)    \n",
    "    test.drop('ID', axis=1, inplace=True)\n",
    "    for name in drop:\n",
    "        train.drop(name, axis=1, inplace=True)    \n",
    "        test.drop(name, axis=1, inplace=True)        \n",
    "\n",
    "    train['zerocount'] = train.apply(lambda x: np.sum(x == 0), axis=1)\n",
    "    test['zerocount'] = test.apply(lambda x: np.sum(x == 0), axis=1)\n",
    "\n",
    "    train['var38'].replace(117310.979016494, -1.0, inplace=True)\n",
    "    test ['var38'].replace(117310.979016494, -1.0, inplace=True)\n",
    "    \n",
    "    train_s = train\n",
    "    test_s = test\n",
    "    result = pd.concat([test_s,train_s])\n",
    "    \n",
    "    #test_s.drop('id', axis=1, inplace=True)\n",
    "    result=result.T.to_dict().values()\n",
    "    train = train_s.T.to_dict().values()\n",
    "    test = test_s.T.to_dict().values()\n",
    "    \n",
    "    vec = DictVectorizer()\n",
    "    vec.fit(result)\n",
    "    train = vec.transform(train)\n",
    "    test = vec.transform(test)\n",
    "    \n",
    "    print(train.shape)\n",
    "    print(test.shape)\n",
    "    \n",
    "    \n",
    "    return train,test\n",
    "\n",
    "def bagged_set(X_t,y_c,model, seed, estimators, xt, update_seed=True):\n",
    "    \n",
    "   # create array object to hold predictions \n",
    "   baggedpred=[ 0.0  for d in range(0, (xt.shape[0]))]\n",
    "   #loop for as many times as we want bags\n",
    "   for n in range (0, estimators):\n",
    "        #shuff;e first, aids in increasing variance and forces different results\n",
    "        #X_t,y_c=shuffle(Xs,ys, random_state=seed+n)\n",
    "          \n",
    "        if update_seed: # update seed if requested, to give a slightly different model\n",
    "            model.set_params(random_state=seed + n)\n",
    "        model.fit(X_t,y_c) # fit model0.0917411475506\n",
    "        preds=model.predict_proba(xt)[:,1] # predict probabilities\n",
    "        # update bag's array\n",
    "        for j in range (0, (xt.shape[0])):           \n",
    "                baggedpred[j]+=preds[j]\n",
    "        #print(\"done bag %d mean %f  \" % (n,meanthis))\n",
    "   # divide with number of bags to create an average estimate            \n",
    "   for j in range (0, len(baggedpred)): \n",
    "                baggedpred[j]/=float(estimators)\n",
    "   # return probabilities            \n",
    "   return np.array(baggedpred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d621c6d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3d621c6d",
    "outputId": "faa3d847-a34f-4291-ca42-0d70bb74ec3a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-fc18cd792a07>:33: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  result=result.T.to_dict().values()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76020, 307)\n",
      "(75818, 307)\n",
      "(76020, 2)\n",
      "(75818, 2)\n",
      "(76020, 309)\n",
      "(75818, 309)\n",
      "kfolder\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n"
     ]
    }
   ],
   "source": [
    "load_data=True      \n",
    "metafolder_train=\"../data/output/train/\"\n",
    "metafolder_test=\"..data/output/test/\"        \n",
    "input_folder=\"../data/input/\"\n",
    "feature_folder=\"../data/output/features/\"\n",
    "SEED=15\n",
    "outset=\"rf_marios_1\" # predic of all files\n",
    "number_of_folds=5 # repeat the CV procedure 10 times to get more precise results       \n",
    "\n",
    "######### Load files ############\n",
    "\n",
    "y=loadcolumn(input_folder+ \"train.csv\",col=370, skip=1, floats=True)\n",
    "ids=loadcolumn(input_folder+ \"test.csv\",col=0, skip=1, floats=True)\n",
    "idstrain=loadcolumn(input_folder+ \"train.csv\",col=0, skip=1, floats=True)\n",
    "keepfold=[0 for k in range(len(y))]\n",
    "\n",
    "if load_data:\n",
    "    X,X_test=all_load_vecorizerr(input_folder+'train.csv',input_folder+'test.csv') \n",
    "    printfile(X,\"Xvector.pkl\")  \n",
    "    printfile(X_test,\"Xtestvector.pkl\")                               \n",
    "    X=load_datas(\"Xvector.pkl\").toarray()\n",
    "    X_test=load_datas(\"Xtestvector.pkl\").toarray()\n",
    "\n",
    "\n",
    "tsn_features=(np.loadtxt(feature_folder+ \"tsne_feats.csv\", delimiter=\",\", skiprows=1, usecols=[1,2]))\n",
    "\n",
    "tsn_features_train=tsn_features[:X.shape[0]]\n",
    "tsn_features_test=tsn_features[X.shape[0]:tsn_features.shape[0]]     \n",
    "\n",
    "print(tsn_features_train.shape)\n",
    "print(tsn_features_test.shape)\n",
    "\n",
    "X=np.column_stack((X,tsn_features_train))     \n",
    "X_test=np.column_stack((X_test,tsn_features_test)) \n",
    "\n",
    "print(X.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "#model to use\n",
    "\n",
    "model=RandomForestClassifier(n_estimators=1200,criterion='entropy',max_depth=10,min_samples_leaf=4,max_features=0.3,\n",
    "                             bootstrap=False,n_jobs=20,random_state=1)   \n",
    "#Create Arrays for meta\n",
    "train_stacker=[ 0.0  for k in range (0,(X.shape[0])) ]\n",
    "test_stacker=[0.0  for k in range (0,(X_test.shape[0]))]\n",
    "\n",
    "# CHECK EVerything in five..it could be more efficient     \n",
    "\n",
    "\n",
    "print(\"kfolder\")\n",
    "\n",
    "#load the 20-fold ids.\n",
    "kfolders=load_ids(input_folder+\"5fold_20times.csv\")  \n",
    "\n",
    "printfile(kfolders,\"kfolder.pkl\")                   \n",
    "kfolders=load_datas(\"kfolder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "952e0c29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "952e0c29",
    "outputId": "f1571c0d-61b3-4f5e-d035-b5c801afa80d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting cross validation with 5 kfolds \n",
      "folder 0  train size: 60790. test size: 15230, cols: 309 \n",
      "folder 0 size train: 60790 size cv: 15230 AUC (fold 1/5): 0.835154\n",
      "folder 0  train size: 60879. test size: 15141, cols: 309 \n",
      "folder 0 size train: 60879 size cv: 15141 AUC (fold 2/5): 0.834723\n",
      "folder 0  train size: 60739. test size: 15281, cols: 309 \n",
      "folder 0 size train: 60739 size cv: 15281 AUC (fold 3/5): 0.837369\n",
      "folder 0  train size: 60752. test size: 15268, cols: 309 \n",
      "folder 0 size train: 60752 size cv: 15268 AUC (fold 4/5): 0.825710\n",
      "folder 0  train size: 60920. test size: 15100, cols: 309 \n",
      "folder 0 size train: 60920 size cv: 15100 AUC (fold 5/5): 0.853032\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 1  train size: 60869. test size: 15151, cols: 309 \n",
      "folder 1 size train: 60869 size cv: 15151 AUC (fold 1/5): 0.840848\n",
      "folder 1  train size: 60833. test size: 15187, cols: 309 \n",
      "folder 1 size train: 60833 size cv: 15187 AUC (fold 2/5): 0.842232\n",
      "folder 1  train size: 60700. test size: 15320, cols: 309 \n",
      "folder 1 size train: 60700 size cv: 15320 AUC (fold 3/5): 0.847623\n",
      "folder 1  train size: 60955. test size: 15065, cols: 309 \n",
      "folder 1 size train: 60955 size cv: 15065 AUC (fold 4/5): 0.823912\n",
      "folder 1  train size: 60723. test size: 15297, cols: 309 \n",
      "folder 1 size train: 60723 size cv: 15297 AUC (fold 5/5): 0.832246\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 2  train size: 60746. test size: 15274, cols: 309 \n",
      "folder 2 size train: 60746 size cv: 15274 AUC (fold 1/5): 0.853974\n",
      "folder 2  train size: 60710. test size: 15310, cols: 309 \n",
      "folder 2 size train: 60710 size cv: 15310 AUC (fold 2/5): 0.830723\n",
      "folder 2  train size: 61055. test size: 14965, cols: 309 \n",
      "folder 2 size train: 61055 size cv: 14965 AUC (fold 3/5): 0.842716\n",
      "folder 2  train size: 60788. test size: 15232, cols: 309 \n",
      "folder 2 size train: 60788 size cv: 15232 AUC (fold 4/5): 0.852180\n",
      "folder 2  train size: 60781. test size: 15239, cols: 309 \n",
      "folder 2 size train: 60781 size cv: 15239 AUC (fold 5/5): 0.816921\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 3  train size: 60889. test size: 15131, cols: 309 \n",
      "folder 3 size train: 60889 size cv: 15131 AUC (fold 1/5): 0.839054\n",
      "folder 3  train size: 60822. test size: 15198, cols: 309 \n",
      "folder 3 size train: 60822 size cv: 15198 AUC (fold 2/5): 0.825265\n",
      "folder 3  train size: 60695. test size: 15325, cols: 309 \n",
      "folder 3 size train: 60695 size cv: 15325 AUC (fold 3/5): 0.837303\n",
      "folder 3  train size: 60830. test size: 15190, cols: 309 \n",
      "folder 3 size train: 60830 size cv: 15190 AUC (fold 4/5): 0.835970\n",
      "folder 3  train size: 60844. test size: 15176, cols: 309 \n",
      "folder 3 size train: 60844 size cv: 15176 AUC (fold 5/5): 0.851968\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 4  train size: 60749. test size: 15271, cols: 309 \n",
      "folder 4 size train: 60749 size cv: 15271 AUC (fold 1/5): 0.838329\n",
      "folder 4  train size: 60899. test size: 15121, cols: 309 \n",
      "folder 4 size train: 60899 size cv: 15121 AUC (fold 2/5): 0.843813\n",
      "folder 4  train size: 60942. test size: 15078, cols: 309 \n",
      "folder 4 size train: 60942 size cv: 15078 AUC (fold 3/5): 0.829979\n",
      "folder 4  train size: 60729. test size: 15291, cols: 309 \n",
      "folder 4 size train: 60729 size cv: 15291 AUC (fold 4/5): 0.838561\n",
      "folder 4  train size: 60761. test size: 15259, cols: 309 \n",
      "folder 4 size train: 60761 size cv: 15259 AUC (fold 5/5): 0.842568\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 5  train size: 60817. test size: 15203, cols: 309 \n",
      "folder 5 size train: 60817 size cv: 15203 AUC (fold 1/5): 0.845464\n",
      "folder 5  train size: 60811. test size: 15209, cols: 309 \n",
      "folder 5 size train: 60811 size cv: 15209 AUC (fold 2/5): 0.837814\n",
      "folder 5  train size: 60951. test size: 15069, cols: 309 \n",
      "folder 5 size train: 60951 size cv: 15069 AUC (fold 3/5): 0.832284\n",
      "folder 5  train size: 60798. test size: 15222, cols: 309 \n",
      "folder 5 size train: 60798 size cv: 15222 AUC (fold 4/5): 0.845630\n",
      "folder 5  train size: 60703. test size: 15317, cols: 309 \n",
      "folder 5 size train: 60703 size cv: 15317 AUC (fold 5/5): 0.832495\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 6  train size: 60903. test size: 15117, cols: 309 \n",
      "folder 6 size train: 60903 size cv: 15117 AUC (fold 1/5): 0.843392\n",
      "folder 6  train size: 60774. test size: 15246, cols: 309 \n",
      "folder 6 size train: 60774 size cv: 15246 AUC (fold 2/5): 0.830221\n",
      "folder 6  train size: 60666. test size: 15354, cols: 309 \n",
      "folder 6 size train: 60666 size cv: 15354 AUC (fold 3/5): 0.841753\n",
      "folder 6  train size: 60880. test size: 15140, cols: 309 \n",
      "folder 6 size train: 60880 size cv: 15140 AUC (fold 4/5): 0.841321\n",
      "folder 6  train size: 60857. test size: 15163, cols: 309 \n",
      "folder 6 size train: 60857 size cv: 15163 AUC (fold 5/5): 0.831110\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 7  train size: 60817. test size: 15203, cols: 309 \n",
      "folder 7 size train: 60817 size cv: 15203 AUC (fold 1/5): 0.840009\n",
      "folder 7  train size: 60868. test size: 15152, cols: 309 \n",
      "folder 7 size train: 60868 size cv: 15152 AUC (fold 2/5): 0.838596\n",
      "folder 7  train size: 60733. test size: 15287, cols: 309 \n",
      "folder 7 size train: 60733 size cv: 15287 AUC (fold 3/5): 0.825951\n",
      "folder 7  train size: 61062. test size: 14958, cols: 309 \n",
      "folder 7 size train: 61062 size cv: 14958 AUC (fold 4/5): 0.838380\n",
      "folder 7  train size: 60600. test size: 15420, cols: 309 \n",
      "folder 7 size train: 60600 size cv: 15420 AUC (fold 5/5): 0.848865\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 8  train size: 60771. test size: 15249, cols: 309 \n",
      "folder 8 size train: 60771 size cv: 15249 AUC (fold 1/5): 0.833448\n",
      "folder 8  train size: 60731. test size: 15289, cols: 309 \n",
      "folder 8 size train: 60731 size cv: 15289 AUC (fold 2/5): 0.838679\n",
      "folder 8  train size: 60927. test size: 15093, cols: 309 \n",
      "folder 8 size train: 60927 size cv: 15093 AUC (fold 3/5): 0.839511\n",
      "folder 8  train size: 60818. test size: 15202, cols: 309 \n",
      "folder 8 size train: 60818 size cv: 15202 AUC (fold 4/5): 0.845496\n",
      "folder 8  train size: 60833. test size: 15187, cols: 309 \n",
      "folder 8 size train: 60833 size cv: 15187 AUC (fold 5/5): 0.826954\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 9  train size: 60927. test size: 15093, cols: 309 \n",
      "folder 9 size train: 60927 size cv: 15093 AUC (fold 1/5): 0.835614\n",
      "folder 9  train size: 60836. test size: 15184, cols: 309 \n",
      "folder 9 size train: 60836 size cv: 15184 AUC (fold 2/5): 0.849443\n",
      "folder 9  train size: 60659. test size: 15361, cols: 309 \n",
      "folder 9 size train: 60659 size cv: 15361 AUC (fold 3/5): 0.821236\n",
      "folder 9  train size: 60873. test size: 15147, cols: 309 \n",
      "folder 9 size train: 60873 size cv: 15147 AUC (fold 4/5): 0.831966\n",
      "folder 9  train size: 60785. test size: 15235, cols: 309 \n",
      "folder 9 size train: 60785 size cv: 15235 AUC (fold 5/5): 0.843484\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 10  train size: 60695. test size: 15325, cols: 309 \n",
      "folder 10 size train: 60695 size cv: 15325 AUC (fold 1/5): 0.835586\n",
      "folder 10  train size: 60800. test size: 15220, cols: 309 \n",
      "folder 10 size train: 60800 size cv: 15220 AUC (fold 2/5): 0.843727\n",
      "folder 10  train size: 60806. test size: 15214, cols: 309 \n",
      "folder 10 size train: 60806 size cv: 15214 AUC (fold 3/5): 0.839378\n",
      "folder 10  train size: 60594. test size: 15426, cols: 309 \n",
      "folder 10 size train: 60594 size cv: 15426 AUC (fold 4/5): 0.839326\n",
      "folder 10  train size: 61185. test size: 14835, cols: 309 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder 10 size train: 61185 size cv: 14835 AUC (fold 5/5): 0.824050\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 11  train size: 60697. test size: 15323, cols: 309 \n",
      "folder 11 size train: 60697 size cv: 15323 AUC (fold 1/5): 0.826186\n",
      "folder 11  train size: 60929. test size: 15091, cols: 309 \n",
      "folder 11 size train: 60929 size cv: 15091 AUC (fold 2/5): 0.849210\n",
      "folder 11  train size: 60806. test size: 15214, cols: 309 \n",
      "folder 11 size train: 60806 size cv: 15214 AUC (fold 3/5): 0.834041\n",
      "folder 11  train size: 60904. test size: 15116, cols: 309 \n",
      "folder 11 size train: 60904 size cv: 15116 AUC (fold 4/5): 0.843976\n",
      "folder 11  train size: 60744. test size: 15276, cols: 309 \n",
      "folder 11 size train: 60744 size cv: 15276 AUC (fold 5/5): 0.830817\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 12  train size: 60707. test size: 15313, cols: 309 \n",
      "folder 12 size train: 60707 size cv: 15313 AUC (fold 1/5): 0.848899\n",
      "folder 12  train size: 60752. test size: 15268, cols: 309 \n",
      "folder 12 size train: 60752 size cv: 15268 AUC (fold 2/5): 0.831244\n",
      "folder 12  train size: 60916. test size: 15104, cols: 309 \n",
      "folder 12 size train: 60916 size cv: 15104 AUC (fold 3/5): 0.831145\n",
      "folder 12  train size: 60806. test size: 15214, cols: 309 \n",
      "folder 12 size train: 60806 size cv: 15214 AUC (fold 4/5): 0.838893\n",
      "folder 12  train size: 60899. test size: 15121, cols: 309 \n",
      "folder 12 size train: 60899 size cv: 15121 AUC (fold 5/5): 0.839977\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 13  train size: 60821. test size: 15199, cols: 309 \n",
      "folder 13 size train: 60821 size cv: 15199 AUC (fold 1/5): 0.823116\n",
      "folder 13  train size: 60994. test size: 15026, cols: 309 \n",
      "folder 13 size train: 60994 size cv: 15026 AUC (fold 2/5): 0.844422\n",
      "folder 13  train size: 60788. test size: 15232, cols: 309 \n",
      "folder 13 size train: 60788 size cv: 15232 AUC (fold 3/5): 0.838722\n",
      "folder 13  train size: 60676. test size: 15344, cols: 309 \n",
      "folder 13 size train: 60676 size cv: 15344 AUC (fold 4/5): 0.833663\n",
      "folder 13  train size: 60801. test size: 15219, cols: 309 \n",
      "folder 13 size train: 60801 size cv: 15219 AUC (fold 5/5): 0.848954\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 14  train size: 60941. test size: 15079, cols: 309 \n",
      "folder 14 size train: 60941 size cv: 15079 AUC (fold 1/5): 0.843077\n",
      "folder 14  train size: 60631. test size: 15389, cols: 309 \n",
      "folder 14 size train: 60631 size cv: 15389 AUC (fold 2/5): 0.847157\n",
      "folder 14  train size: 60718. test size: 15302, cols: 309 \n",
      "folder 14 size train: 60718 size cv: 15302 AUC (fold 3/5): 0.828704\n",
      "folder 14  train size: 60897. test size: 15123, cols: 309 \n",
      "folder 14 size train: 60897 size cv: 15123 AUC (fold 4/5): 0.834571\n",
      "folder 14  train size: 60893. test size: 15127, cols: 309 \n",
      "folder 14 size train: 60893 size cv: 15127 AUC (fold 5/5): 0.836453\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 15  train size: 60754. test size: 15266, cols: 309 \n",
      "folder 15 size train: 60754 size cv: 15266 AUC (fold 1/5): 0.849515\n",
      "folder 15  train size: 60813. test size: 15207, cols: 309 \n",
      "folder 15 size train: 60813 size cv: 15207 AUC (fold 2/5): 0.840325\n",
      "folder 15  train size: 60955. test size: 15065, cols: 309 \n",
      "folder 15 size train: 60955 size cv: 15065 AUC (fold 3/5): 0.829796\n",
      "folder 15  train size: 60704. test size: 15316, cols: 309 \n",
      "folder 15 size train: 60704 size cv: 15316 AUC (fold 4/5): 0.833518\n",
      "folder 15  train size: 60854. test size: 15166, cols: 309 \n",
      "folder 15 size train: 60854 size cv: 15166 AUC (fold 5/5): 0.838770\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 16  train size: 60876. test size: 15144, cols: 309 \n",
      "folder 16 size train: 60876 size cv: 15144 AUC (fold 1/5): 0.833560\n",
      "folder 16  train size: 60785. test size: 15235, cols: 309 \n",
      "folder 16 size train: 60785 size cv: 15235 AUC (fold 2/5): 0.826398\n",
      "folder 16  train size: 60817. test size: 15203, cols: 309 \n",
      "folder 16 size train: 60817 size cv: 15203 AUC (fold 3/5): 0.849534\n",
      "folder 16  train size: 60911. test size: 15109, cols: 309 \n",
      "folder 16 size train: 60911 size cv: 15109 AUC (fold 4/5): 0.838919\n",
      "folder 16  train size: 60691. test size: 15329, cols: 309 \n",
      "folder 16 size train: 60691 size cv: 15329 AUC (fold 5/5): 0.836917\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 17  train size: 60996. test size: 15024, cols: 309 \n",
      "folder 17 size train: 60996 size cv: 15024 AUC (fold 1/5): 0.828814\n",
      "folder 17  train size: 60808. test size: 15212, cols: 309 \n",
      "folder 17 size train: 60808 size cv: 15212 AUC (fold 2/5): 0.843194\n",
      "folder 17  train size: 60770. test size: 15250, cols: 309 \n",
      "folder 17 size train: 60770 size cv: 15250 AUC (fold 3/5): 0.844807\n",
      "folder 17  train size: 60767. test size: 15253, cols: 309 \n",
      "folder 17 size train: 60767 size cv: 15253 AUC (fold 4/5): 0.829957\n",
      "folder 17  train size: 60739. test size: 15281, cols: 309 \n",
      "folder 17 size train: 60739 size cv: 15281 AUC (fold 5/5): 0.839106\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 18  train size: 60781. test size: 15239, cols: 309 \n",
      "folder 18 size train: 60781 size cv: 15239 AUC (fold 1/5): 0.826792\n",
      "folder 18  train size: 60992. test size: 15028, cols: 309 \n",
      "folder 18 size train: 60992 size cv: 15028 AUC (fold 2/5): 0.837101\n",
      "folder 18  train size: 60814. test size: 15206, cols: 309 \n",
      "folder 18 size train: 60814 size cv: 15206 AUC (fold 3/5): 0.850499\n",
      "folder 18  train size: 60679. test size: 15341, cols: 309 \n",
      "folder 18 size train: 60679 size cv: 15341 AUC (fold 4/5): 0.841258\n",
      "folder 18  train size: 60814. test size: 15206, cols: 309 \n",
      "folder 18 size train: 60814 size cv: 15206 AUC (fold 5/5): 0.834838\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 19  train size: 60774. test size: 15246, cols: 309 \n",
      "folder 19 size train: 60774 size cv: 15246 AUC (fold 1/5): 0.836186\n",
      "folder 19  train size: 60653. test size: 15367, cols: 309 \n",
      "folder 19 size train: 60653 size cv: 15367 AUC (fold 2/5): 0.829682\n",
      "folder 19  train size: 60863. test size: 15157, cols: 309 \n",
      "folder 19 size train: 60863 size cv: 15157 AUC (fold 3/5): 0.851516\n",
      "folder 19  train size: 60897. test size: 15123, cols: 309 \n",
      "folder 19 size train: 60897 size cv: 15123 AUC (fold 4/5): 0.830693\n",
      "folder 19  train size: 60893. test size: 15127, cols: 309 \n",
      "folder 19 size train: 60893 size cv: 15127 AUC (fold 5/5): 0.841835\n",
      "==============================================================================================\n",
      " Grand AUC: 0.838932\n",
      " printing train datasets \n",
      " making test predictions \n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..data/output/test/rf_marios_1.test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-48cdc8671e59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m \u001b[0mprintfilcsve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_stacker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mmetafolder_test\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0moutset\u001b[0m  \u001b[1;33m+\u001b[0m \u001b[1;34m\".test.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"ID,TARGET\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-5dd9ffdbda95>\u001b[0m in \u001b[0;36mprintfilcsve\u001b[1;34m(X, filename, headers)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprintfilcsve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msavetxt\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msavetxt\u001b[1;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;31m# datasource doesn't support creating a new file ...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1366\u001b[1;33m         \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1367\u001b[0m         \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1368\u001b[0m         \u001b[0mown_fh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '..data/output/test/rf_marios_1.test.csv'"
     ]
    }
   ],
   "source": [
    "fcount=0\n",
    "trackingfile=open(outset + \"_tracker.csv\",\"w\")\n",
    "#number_of_folds=0\n",
    "#X,y=shuffle(X,y, random_state=SEED) # Shuffle since the data is ordered by time\n",
    "for kfolder in kfolders:\n",
    "    mean_kapa = 0.0\n",
    "    i=0 # iterator counter\n",
    "    print (\"starting cross validation with %d kfolds \" % (number_of_folds))\n",
    "    if number_of_folds>0:\n",
    "        for train_index, test_index in kfolder:\n",
    "            # creaning and validation sets\n",
    "            X_train, X_cv = X[train_index], X[test_index]\n",
    "            y_train, y_cv = np.array(y)[train_index], np.array(y)[test_index]\n",
    "\n",
    "            print (\"folder %d  train size: %d. test size: %d, cols: %d \" % (fcount, (X_train.shape[0]) ,(X_cv.shape[0]) ,(X_train.shape[1]) ))\n",
    "\n",
    "\n",
    "            preds=bagged_set(X_train,y_train,model, SEED, 1, X_cv, update_seed=True)\n",
    "\n",
    "            # compute Loglikelihood metric for this CV fold\n",
    "            #scalepreds(preds)     \n",
    "            kapa = roc_auc_score(y_cv,preds)\n",
    "            print(\"folder %d size train: %d size cv: %d AUC (fold %d/%d): %f\" % (fcount,(X_train.shape[0]), (X_cv.shape[0]), i + 1, number_of_folds, kapa))\n",
    "            trackingfile.write(\"folder %d size train: %d size cv: %d AUC (fold %d/%d): %f\\n\" % (fcount,(X_train.shape[0]), (X_cv.shape[0]), i + 1, number_of_folds, kapa))\n",
    "            mean_kapa += kapa\n",
    "            #save the results\n",
    "            no=0\n",
    "            for real_index in test_index:\n",
    "                     train_stacker[real_index]+=(preds[no])\n",
    "                     keepfold[real_index]=i\n",
    "                     no+=1\n",
    "            i+=1\n",
    "    fcount+=1\n",
    "    print(\"==============================================================================================\")\n",
    "    trackingfile.write(\"==============================================================================================\\n\")\n",
    "for u in range(0,len(train_stacker)):\n",
    "    train_stacker[u]/=float(len(kfolders))\n",
    "grand_auc=roc_auc_score(y, train_stacker)\n",
    "print (\" Grand AUC: %f\" % (grand_auc) )\n",
    "trackingfile.write(\" Grand AUC: %f\\n\" % (grand_auc))  \n",
    "trackingfile.close()\n",
    "if (number_of_folds)>0:\n",
    "    mean_kapa/=number_of_folds\n",
    "    print (\" printing train datasets \")\n",
    "    printfilcsve(np.column_stack((np.array(idstrain),np.array(train_stacker))), metafolder_train+ outset  + \".train.csv\",\"ID,TARGET\")  \n",
    "    #printfilcsve(np.column_stack((np.array(idstrain),np.array(keepfold))),   \"id_fold.csv\",\"ID,FOLD\")\n",
    "\n",
    "#woe_train, woe_cv= convert_to_woe(np.round(X,2),y, np.round(X_test,2), seed=1, cvals=5, roundings=2, columns=None)\n",
    "\n",
    "#X=np.column_stack((X,woe_train))\n",
    "#X_test=np.column_stack((X_test,woe_cv))      \n",
    "print (\" making test predictions \")        \n",
    "preds=bagged_set(X, y,model, SEED, 4, X_test, update_seed=True) \n",
    "\n",
    "for pr in range (0,len(preds)):            \n",
    "            test_stacker[pr]=(preds[pr]) \n",
    "\n",
    "preds=np.array(preds)\n",
    "printfilcsve(np.column_stack((np.array(ids),np.array(test_stacker))),  metafolder_test+ outset  + \".test.csv\",\"ID,TARGET\")                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dGsOc80orJ0v",
   "metadata": {
    "id": "dGsOc80orJ0v"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RF_Marios_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
