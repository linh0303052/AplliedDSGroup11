{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4e6de5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7ae43aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadcolumn(filename,col=4, skip=1, floats=True):\n",
    "    pred=[]\n",
    "    op=open(filename,'r')\n",
    "    if skip==1:\n",
    "        op.readline() #header\n",
    "    for line in op:\n",
    "        line=line.replace('\\n','')\n",
    "        sps=line.split(',')\n",
    "        #load always the last columns\n",
    "        if floats:\n",
    "            pred.append(float(sps[col]))\n",
    "        else :\n",
    "            pred.append(str(sps[col]))\n",
    "    op.close()\n",
    "    return pred            \n",
    "\n",
    "    \n",
    "def load_datas(filename):\n",
    "\n",
    "    return joblib.load(filename)\n",
    "\n",
    "def printfile(X, filename):\n",
    "\n",
    "    joblib.dump((X), filename)\n",
    "    \n",
    "def printfilcsve(X, filename, headers):\n",
    "\n",
    "    np.savetxt(filename,X, header=headers) \n",
    "\n",
    "    \n",
    "def load_ids(id_file):\n",
    "\n",
    "    idss=loadcolumn(id_file,col=1, skip=1, floats=True)\n",
    "    id_list=[ [] ,[] , [], [] , []]\n",
    "    for g in range(0,len(idss)):\n",
    "        id_list[int(idss[g])].append(g)\n",
    "    biglist=[]\n",
    "    for k in range(5):\n",
    "        training_ids=[s for s in range(0,len(idss)) if s not in id_list[k] ]\n",
    "        biglist.append([training_ids,id_list[k] ])\n",
    "        print(len(biglist), len(biglist[0]))\n",
    "    return biglist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3111092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of target=76020\n",
      "model kNN_Marios_1 auc 0.797451 mean train/test 0.034809/0.034524 \n",
      "model NN_Marios_1 auc 0.817421 mean train/test 0.028328/0.028195 \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-03ee3c22f5d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mmean_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmini_xtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model %s auc %f mean train/test %f/%f \"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodelname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmini_xtrain\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mmean_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmean_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mXmetatrain\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mXmetatrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmini_xtrain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mXmetatest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmini_xtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "metafolder_train=\"../data/output/train/\"\n",
    "metafolder_test=\"../data/output/test/\"    \n",
    "input_folder=\"../data/input/\"        \n",
    "\n",
    "######### Load files ############\n",
    "y=loadcolumn(input_folder+ \"train.csv\",col=370, skip=1, floats=True)\n",
    "\n",
    "#variables to load\n",
    "\n",
    "meta = [\"kNN_Marios_1\", \"NN_Marios_1\"]  \n",
    "\n",
    "\n",
    "print(\"len of target=%d\" % (len(y))) # reconciliation check\n",
    "\n",
    "Xmetatrain=None\n",
    "Xmetatest=None   \n",
    "#append all the predictions into 1 list (array)\n",
    "for modelname in meta :\n",
    "    mini_xtrain=np.loadtxt(metafolder_train+ modelname + '.train.csv', skiprows=1, usecols=[1])\n",
    "    mini_xtest=np.loadtxt(metafolder_test + modelname + '.test.csv', skiprows=1, usecols=[1])  \n",
    "    mean_train=np.mean(mini_xtrain)\n",
    "    mean_test=np.mean(mini_xtest)               \n",
    "    print(\"model %s auc %f mean train/test %f/%f \" % (modelname,roc_auc_score(y,mini_xtrain) ,mean_train,mean_test)) \n",
    "    if (Xmetatrain==None).all():\n",
    "        Xmetatrain=mini_xtrain\n",
    "        Xmetatest=mini_xtest\n",
    "    else :\n",
    "        Xmetatrain=np.column_stack((Xmetatrain,mini_xtrain))\n",
    "        Xmetatest=np.column_stack((Xmetatest,mini_xtest))\n",
    "# convert my scores to list\n",
    "\n",
    "X=Xmetatrain\n",
    "X_test=Xmetatest\n",
    "\n",
    "\n",
    "np.savetxt(metafolder_train+ \"marios_models_V\" + str(len(meta)) + \".train.csv\", X , header=\" \".join([k for k in meta])) \n",
    "np.savetxt(metafolder_test+ \"marios_models_V\" + str(len(meta)) + \".test.csv\", X_test , header=\" \".join([k for k in meta]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5f5649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0947cf81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
