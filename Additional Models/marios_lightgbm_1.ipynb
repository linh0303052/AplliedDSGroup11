{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 72531,
     "status": "ok",
     "timestamp": 1641208386183,
     "user": {
      "displayName": "Gia Bảo Hoàng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjqt6XzIPIij_tyINjDMkzMWqrOEsKV13mAIvXdvg=s64",
      "userId": "04263929385004353036"
     },
     "user_tz": -420
    },
    "id": "w6Tvndcd9vdM",
    "outputId": "48e3e647-4e8f-49bb-b56f-c8e09c054bd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive._mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1641208386185,
     "user": {
      "displayName": "Gia Bảo Hoàng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjqt6XzIPIij_tyINjDMkzMWqrOEsKV13mAIvXdvg=s64",
      "userId": "04263929385004353036"
     },
     "user_tz": -420
    },
    "id": "SYEnulFb-E4q",
    "outputId": "ed46deb6-c6fa-48a3-a0a6-6f4e8c8e007b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/santander_2016-master\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/My\\ Drive/santander_2016-master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8595,
     "status": "ok",
     "timestamp": 1641208394772,
     "user": {
      "displayName": "Gia Bảo Hoàng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjqt6XzIPIij_tyINjDMkzMWqrOEsKV13mAIvXdvg=s64",
      "userId": "04263929385004353036"
     },
     "user_tz": -420
    },
    "id": "CpkG5lxdADGY",
    "outputId": "41db7899-3c5a-415c-a94d-85f7d267e99a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from mlxtend) (57.4.0)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.0.1)\n",
      "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (3.2.2)\n",
      "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.19.5)\n",
      "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.1.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (3.0.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.1->mlxtend) (2018.9)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=1.5.1->mlxtend) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->mlxtend) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->mlxtend) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iC1nbYNKOMoL"
   },
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 809,
     "status": "ok",
     "timestamp": 1641208409101,
     "user": {
      "displayName": "Gia Bảo Hoàng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjqt6XzIPIij_tyINjDMkzMWqrOEsKV13mAIvXdvg=s64",
      "userId": "04263929385004353036"
     },
     "user_tz": -420
    },
    "id": "PkJa5Wzf6PE8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "import sys\n",
    "sys.modules['sklearn.externals.joblib'] = joblib\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4912,
     "status": "ok",
     "timestamp": 1641208400793,
     "user": {
      "displayName": "Gia Bảo Hoàng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjqt6XzIPIij_tyINjDMkzMWqrOEsKV13mAIvXdvg=s64",
      "userId": "04263929385004353036"
     },
     "user_tz": -420
    },
    "id": "6ym52ej_g4Y3",
    "outputId": "5ba3fc37-e327-4dba-8b7f-d54a71cbbe4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /usr/local/lib/python3.7/dist-packages (2.2.3)\n",
      "Collecting lightgbm\n",
      "  Downloading lightgbm-3.3.1-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 5.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.0.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.4.1)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm) (0.37.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.19.5)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.22.0->lightgbm) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.22.0->lightgbm) (3.0.0)\n",
      "Installing collected packages: lightgbm\n",
      "  Attempting uninstall: lightgbm\n",
      "    Found existing installation: lightgbm 2.2.3\n",
      "    Uninstalling lightgbm-2.2.3:\n",
      "      Successfully uninstalled lightgbm-2.2.3\n",
      "Successfully installed lightgbm-3.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 498,
     "status": "ok",
     "timestamp": 1641209032625,
     "user": {
      "displayName": "Gia Bảo Hoàng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjqt6XzIPIij_tyINjDMkzMWqrOEsKV13mAIvXdvg=s64",
      "userId": "04263929385004353036"
     },
     "user_tz": -420
    },
    "id": "KR6wYL65pdCv"
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đây là sử dụng mô hình LightGBM, chạy trên cách tiền xử lý và dự đoán mô hình của Marios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadcolumn(filename,col=4, skip=1, floats=True):\n",
    "    pred=[]\n",
    "    op=open(filename,'r')\n",
    "    if skip==1:\n",
    "        op.readline() #header\n",
    "    for line in op:\n",
    "        line=line.replace('\\n','')\n",
    "        sps=line.split(',')\n",
    "        #load always the last columns\n",
    "        if floats:\n",
    "            pred.append(float(sps[col]))\n",
    "        else :\n",
    "            pred.append(str(sps[col]))\n",
    "    op.close()\n",
    "    return np.array(pred)            \n",
    "\n",
    "    \n",
    "def load_datas(filename):\n",
    "\n",
    "    return joblib.load(filename)\n",
    "\n",
    "def printfile(X, filename):\n",
    "\n",
    "    joblib.dump((X), filename)\n",
    "    \n",
    "def printfilcsve(X, filename, headers):\n",
    "\n",
    "    np.savetxt(filename,X, header=headers) \n",
    "    \n",
    "    \n",
    "def load_ids(id_file, cols=20):\n",
    "    verybiglist=[]\n",
    "    for s in range(0,cols):\n",
    "        idss=loadcolumn(id_file,col=s, skip=1, floats=True)\n",
    "        id_list=[ [] ,[] , [], [] , []]\n",
    "        id_dict=[ defaultdict(int) ,defaultdict(int) , defaultdict(int), defaultdict(int) , defaultdict(int)]\n",
    "        for g in range(0,len(idss)):\n",
    "            id_list[int(idss[g])].append(g)\n",
    "            id_dict[int(idss[g])][g]=1\n",
    "        biglist=[]\n",
    "        for k in range(5):\n",
    "            training_ids=[s for s in range(0,len(idss)) if s not in id_dict[k] ]\n",
    "            biglist.append([training_ids,id_list[k] ])\n",
    "            print(len(biglist), len(biglist[0]))\n",
    "        verybiglist.append(biglist)\n",
    "            \n",
    "    return verybiglist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_load_vecorizerr(tr,te,drop=[\"ind_var2_0\",\"ind_var2\",\"ind_var27_0\",\"ind_var28_0\",\"ind_var28\",\"ind_var27\",\n",
    "\"ind_var41\",\"ind_var46_0\",\"ind_var46\",\"num_var27_0\",\"num_var28_0\",\"num_var28\",\"num_var27\",\"num_var41\",\"num_var46_0\",\n",
    "\"num_var46\",\"saldo_var28\",\"saldo_var27\",\"saldo_var41\",\"saldo_var46\",\"imp_amort_var18_hace3\",\"imp_amort_var34_hace3\",\n",
    "\"imp_reemb_var13_hace3\",\"imp_reemb_var33_hace3\",\"imp_trasp_var17_out_hace3\",\"imp_trasp_var33_out_hace3\",\n",
    "\"num_var2_0_ult1\",\"num_var2_ult1\",\"num_reemb_var13_hace3\",\"num_reemb_var33_hace3\",\"num_trasp_var17_out_hace3\",\n",
    "\"num_trasp_var33_out_hace3\",\"saldo_var2_ult1\",\"saldo_medio_var13_medio_hace3\",\"ind_var6_0\",\"ind_var6\",\n",
    "\"ind_var13_medio_0\",\"ind_var18_0\",\"ind_var26_0\",\"ind_var25_0\",\"ind_var32_0\",\"ind_var34_0\",\"ind_var37_0\",\n",
    "\"ind_var40\",\"num_var6_0\",\"num_var6\",\"num_var13_medio_0\",\"num_var18_0\",\"num_var26_0\",\"num_var25_0\",\"num_var32_0\",\n",
    "\"num_var34_0\",\"num_var37_0\",\"num_var40\",\"saldo_var6\",\"saldo_var13_medio\",\"delta_imp_reemb_var13_1y3\",\n",
    "\"delta_imp_reemb_var17_1y3\",\"delta_imp_reemb_var33_1y3\",\"delta_imp_trasp_var17_in_1y3\",\"delta_imp_trasp_var17_out_1y3\",\n",
    "\"delta_imp_trasp_var33_in_1y3\",\"delta_imp_trasp_var33_out_1y3\"]):\n",
    "\n",
    "    train  = pd.read_csv(tr, sep=',',quotechar='\"')\n",
    "    test  = pd.read_csv(te, sep=',',quotechar='\"')\n",
    "    train.drop('ID', axis=1, inplace=True)\n",
    "    train.drop('TARGET', axis=1, inplace=True)    \n",
    "    test.drop('ID', axis=1, inplace=True)\n",
    "    for name in drop:\n",
    "        train.drop(name, axis=1, inplace=True)    \n",
    "        test.drop(name, axis=1, inplace=True)        \n",
    "\n",
    "    train['zerocount'] = train.apply(lambda x: np.sum(x == 0), axis=1)\n",
    "    test['zerocount'] = test.apply(lambda x: np.sum(x == 0), axis=1)\n",
    "\n",
    "    train['var38'].replace(117310.979016494, -1.0, inplace=True)\n",
    "    test ['var38'].replace(117310.979016494, -1.0, inplace=True)\n",
    "    \n",
    "    train_s = train\n",
    "    test_s = test\n",
    "    result = pd.concat([test_s,train_s])\n",
    "    \n",
    "    #test_s.drop('id', axis=1, inplace=True)\n",
    "    result=result.T.to_dict().values()\n",
    "    train = train_s.T.to_dict().values()\n",
    "    test = test_s.T.to_dict().values()\n",
    "    \n",
    "    vec = DictVectorizer()\n",
    "    vec.fit(result)\n",
    "    train = vec.transform(train)\n",
    "    test = vec.transform(test)\n",
    "    \n",
    "    print(train.shape)\n",
    "    print(test.shape)    \n",
    "    \n",
    "    \n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagged_set(X_t,y_c,model, seed, estimators, xt, update_seed=True):\n",
    "    \n",
    "   # create array object to hold predictions \n",
    "   baggedpred=[ 0.0  for d in range(0, (xt.shape[0]))]\n",
    "    \n",
    "   for n in range (0, estimators):\n",
    "          \n",
    "        if update_seed:\n",
    "            model.set_params(random_state=seed + n)\n",
    "        model.fit(X_t,y_c)\n",
    "        preds=model.predict_proba(xt)[:,1]\n",
    "       \n",
    "        for j in range (0, (xt.shape[0])):           \n",
    "                baggedpred[j]+=preds[j]\n",
    "                \n",
    "   for j in range (0, len(baggedpred)): \n",
    "                baggedpred[j]/=float(estimators)\n",
    "             \n",
    "   return np.array(baggedpred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7389636,
     "status": "ok",
     "timestamp": 1641217287529,
     "user": {
      "displayName": "Gia Bảo Hoàng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjqt6XzIPIij_tyINjDMkzMWqrOEsKV13mAIvXdvg=s64",
      "userId": "04263929385004353036"
     },
     "user_tz": -420
    },
    "id": "QUmTWuN9pJf5",
    "outputId": "7964f042-c498-45d6-cb5e-8e59609f06c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:84: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76020, 307)\n",
      "(75818, 307)\n",
      "(76020, 2)\n",
      "(75818, 2)\n",
      "(76020, 309)\n",
      "(75818, 309)\n",
      "(76020, 9)\n",
      "(75818, 9)\n",
      "(76020, 318)\n",
      "(75818, 318)\n",
      "kfolder\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "1 2\n",
      "2 2\n",
      "3 2\n",
      "4 2\n",
      "5 2\n",
      "starting cross validation with 5 kfolds \n",
      "folder 0  train size: 60790. test size: 15230, cols: 318 \n",
      "folder 0 size train: 60790 size cv: 15230 AUC (fold 1/5): 0.828036\n",
      "folder 0  train size: 60879. test size: 15141, cols: 318 \n",
      "folder 0 size train: 60879 size cv: 15141 AUC (fold 2/5): 0.824363\n",
      "folder 0  train size: 60739. test size: 15281, cols: 318 \n",
      "folder 0 size train: 60739 size cv: 15281 AUC (fold 3/5): 0.829903\n",
      "folder 0  train size: 60752. test size: 15268, cols: 318 \n",
      "folder 0 size train: 60752 size cv: 15268 AUC (fold 4/5): 0.814330\n",
      "folder 0  train size: 60920. test size: 15100, cols: 318 \n",
      "folder 0 size train: 60920 size cv: 15100 AUC (fold 5/5): 0.842352\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 1  train size: 60869. test size: 15151, cols: 318 \n",
      "folder 1 size train: 60869 size cv: 15151 AUC (fold 1/5): 0.831461\n",
      "folder 1  train size: 60833. test size: 15187, cols: 318 \n",
      "folder 1 size train: 60833 size cv: 15187 AUC (fold 2/5): 0.833140\n",
      "folder 1  train size: 60700. test size: 15320, cols: 318 \n",
      "folder 1 size train: 60700 size cv: 15320 AUC (fold 3/5): 0.842547\n",
      "folder 1  train size: 60955. test size: 15065, cols: 318 \n",
      "folder 1 size train: 60955 size cv: 15065 AUC (fold 4/5): 0.810933\n",
      "folder 1  train size: 60723. test size: 15297, cols: 318 \n",
      "folder 1 size train: 60723 size cv: 15297 AUC (fold 5/5): 0.825363\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 2  train size: 60746. test size: 15274, cols: 318 \n",
      "folder 2 size train: 60746 size cv: 15274 AUC (fold 1/5): 0.842387\n",
      "folder 2  train size: 60710. test size: 15310, cols: 318 \n",
      "folder 2 size train: 60710 size cv: 15310 AUC (fold 2/5): 0.817522\n",
      "folder 2  train size: 61055. test size: 14965, cols: 318 \n",
      "folder 2 size train: 61055 size cv: 14965 AUC (fold 3/5): 0.835246\n",
      "folder 2  train size: 60788. test size: 15232, cols: 318 \n",
      "folder 2 size train: 60788 size cv: 15232 AUC (fold 4/5): 0.842493\n",
      "folder 2  train size: 60781. test size: 15239, cols: 318 \n",
      "folder 2 size train: 60781 size cv: 15239 AUC (fold 5/5): 0.808569\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 3  train size: 60889. test size: 15131, cols: 318 \n",
      "folder 3 size train: 60889 size cv: 15131 AUC (fold 1/5): 0.828347\n",
      "folder 3  train size: 60822. test size: 15198, cols: 318 \n",
      "folder 3 size train: 60822 size cv: 15198 AUC (fold 2/5): 0.813616\n",
      "folder 3  train size: 60695. test size: 15325, cols: 318 \n",
      "folder 3 size train: 60695 size cv: 15325 AUC (fold 3/5): 0.825926\n",
      "folder 3  train size: 60830. test size: 15190, cols: 318 \n",
      "folder 3 size train: 60830 size cv: 15190 AUC (fold 4/5): 0.827301\n",
      "folder 3  train size: 60844. test size: 15176, cols: 318 \n",
      "folder 3 size train: 60844 size cv: 15176 AUC (fold 5/5): 0.844570\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 4  train size: 60749. test size: 15271, cols: 318 \n",
      "folder 4 size train: 60749 size cv: 15271 AUC (fold 1/5): 0.825382\n",
      "folder 4  train size: 60899. test size: 15121, cols: 318 \n",
      "folder 4 size train: 60899 size cv: 15121 AUC (fold 2/5): 0.835603\n",
      "folder 4  train size: 60942. test size: 15078, cols: 318 \n",
      "folder 4 size train: 60942 size cv: 15078 AUC (fold 3/5): 0.815166\n",
      "folder 4  train size: 60729. test size: 15291, cols: 318 \n",
      "folder 4 size train: 60729 size cv: 15291 AUC (fold 4/5): 0.830568\n",
      "folder 4  train size: 60761. test size: 15259, cols: 318 \n",
      "folder 4 size train: 60761 size cv: 15259 AUC (fold 5/5): 0.836406\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 5  train size: 60817. test size: 15203, cols: 318 \n",
      "folder 5 size train: 60817 size cv: 15203 AUC (fold 1/5): 0.836121\n",
      "folder 5  train size: 60811. test size: 15209, cols: 318 \n",
      "folder 5 size train: 60811 size cv: 15209 AUC (fold 2/5): 0.831400\n",
      "folder 5  train size: 60951. test size: 15069, cols: 318 \n",
      "folder 5 size train: 60951 size cv: 15069 AUC (fold 3/5): 0.825589\n",
      "folder 5  train size: 60798. test size: 15222, cols: 318 \n",
      "folder 5 size train: 60798 size cv: 15222 AUC (fold 4/5): 0.835203\n",
      "folder 5  train size: 60703. test size: 15317, cols: 318 \n",
      "folder 5 size train: 60703 size cv: 15317 AUC (fold 5/5): 0.819554\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 6  train size: 60903. test size: 15117, cols: 318 \n",
      "folder 6 size train: 60903 size cv: 15117 AUC (fold 1/5): 0.837988\n",
      "folder 6  train size: 60774. test size: 15246, cols: 318 \n",
      "folder 6 size train: 60774 size cv: 15246 AUC (fold 2/5): 0.820470\n",
      "folder 6  train size: 60666. test size: 15354, cols: 318 \n",
      "folder 6 size train: 60666 size cv: 15354 AUC (fold 3/5): 0.831860\n",
      "folder 6  train size: 60880. test size: 15140, cols: 318 \n",
      "folder 6 size train: 60880 size cv: 15140 AUC (fold 4/5): 0.831393\n",
      "folder 6  train size: 60857. test size: 15163, cols: 318 \n",
      "folder 6 size train: 60857 size cv: 15163 AUC (fold 5/5): 0.820823\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 7  train size: 60817. test size: 15203, cols: 318 \n",
      "folder 7 size train: 60817 size cv: 15203 AUC (fold 1/5): 0.830599\n",
      "folder 7  train size: 60868. test size: 15152, cols: 318 \n",
      "folder 7 size train: 60868 size cv: 15152 AUC (fold 2/5): 0.824111\n",
      "folder 7  train size: 60733. test size: 15287, cols: 318 \n",
      "folder 7 size train: 60733 size cv: 15287 AUC (fold 3/5): 0.811613\n",
      "folder 7  train size: 61062. test size: 14958, cols: 318 \n",
      "folder 7 size train: 61062 size cv: 14958 AUC (fold 4/5): 0.833339\n",
      "folder 7  train size: 60600. test size: 15420, cols: 318 \n",
      "folder 7 size train: 60600 size cv: 15420 AUC (fold 5/5): 0.842709\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 8  train size: 60771. test size: 15249, cols: 318 \n",
      "folder 8 size train: 60771 size cv: 15249 AUC (fold 1/5): 0.819208\n",
      "folder 8  train size: 60731. test size: 15289, cols: 318 \n",
      "folder 8 size train: 60731 size cv: 15289 AUC (fold 2/5): 0.830144\n",
      "folder 8  train size: 60927. test size: 15093, cols: 318 \n",
      "folder 8 size train: 60927 size cv: 15093 AUC (fold 3/5): 0.826008\n",
      "folder 8  train size: 60818. test size: 15202, cols: 318 \n",
      "folder 8 size train: 60818 size cv: 15202 AUC (fold 4/5): 0.836884\n",
      "folder 8  train size: 60833. test size: 15187, cols: 318 \n",
      "folder 8 size train: 60833 size cv: 15187 AUC (fold 5/5): 0.826152\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 9  train size: 60927. test size: 15093, cols: 318 \n",
      "folder 9 size train: 60927 size cv: 15093 AUC (fold 1/5): 0.828037\n",
      "folder 9  train size: 60836. test size: 15184, cols: 318 \n",
      "folder 9 size train: 60836 size cv: 15184 AUC (fold 2/5): 0.840862\n",
      "folder 9  train size: 60659. test size: 15361, cols: 318 \n",
      "folder 9 size train: 60659 size cv: 15361 AUC (fold 3/5): 0.808823\n",
      "folder 9  train size: 60873. test size: 15147, cols: 318 \n",
      "folder 9 size train: 60873 size cv: 15147 AUC (fold 4/5): 0.825502\n",
      "folder 9  train size: 60785. test size: 15235, cols: 318 \n",
      "folder 9 size train: 60785 size cv: 15235 AUC (fold 5/5): 0.833716\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 10  train size: 60695. test size: 15325, cols: 318 \n",
      "folder 10 size train: 60695 size cv: 15325 AUC (fold 1/5): 0.832748\n",
      "folder 10  train size: 60800. test size: 15220, cols: 318 \n",
      "folder 10 size train: 60800 size cv: 15220 AUC (fold 2/5): 0.841999\n",
      "folder 10  train size: 60806. test size: 15214, cols: 318 \n",
      "folder 10 size train: 60806 size cv: 15214 AUC (fold 3/5): 0.828086\n",
      "folder 10  train size: 60594. test size: 15426, cols: 318 \n",
      "folder 10 size train: 60594 size cv: 15426 AUC (fold 4/5): 0.828745\n",
      "folder 10  train size: 61185. test size: 14835, cols: 318 \n",
      "folder 10 size train: 61185 size cv: 14835 AUC (fold 5/5): 0.812566\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 11  train size: 60697. test size: 15323, cols: 318 \n",
      "folder 11 size train: 60697 size cv: 15323 AUC (fold 1/5): 0.814689\n",
      "folder 11  train size: 60929. test size: 15091, cols: 318 \n",
      "folder 11 size train: 60929 size cv: 15091 AUC (fold 2/5): 0.840588\n",
      "folder 11  train size: 60806. test size: 15214, cols: 318 \n",
      "folder 11 size train: 60806 size cv: 15214 AUC (fold 3/5): 0.830650\n",
      "folder 11  train size: 60904. test size: 15116, cols: 318 \n",
      "folder 11 size train: 60904 size cv: 15116 AUC (fold 4/5): 0.836043\n",
      "folder 11  train size: 60744. test size: 15276, cols: 318 \n",
      "folder 11 size train: 60744 size cv: 15276 AUC (fold 5/5): 0.818236\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 12  train size: 60707. test size: 15313, cols: 318 \n",
      "folder 12 size train: 60707 size cv: 15313 AUC (fold 1/5): 0.842347\n",
      "folder 12  train size: 60752. test size: 15268, cols: 318 \n",
      "folder 12 size train: 60752 size cv: 15268 AUC (fold 2/5): 0.820265\n",
      "folder 12  train size: 60916. test size: 15104, cols: 318 \n",
      "folder 12 size train: 60916 size cv: 15104 AUC (fold 3/5): 0.822949\n",
      "folder 12  train size: 60806. test size: 15214, cols: 318 \n",
      "folder 12 size train: 60806 size cv: 15214 AUC (fold 4/5): 0.828505\n",
      "folder 12  train size: 60899. test size: 15121, cols: 318 \n",
      "folder 12 size train: 60899 size cv: 15121 AUC (fold 5/5): 0.831964\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 13  train size: 60821. test size: 15199, cols: 318 \n",
      "folder 13 size train: 60821 size cv: 15199 AUC (fold 1/5): 0.813956\n",
      "folder 13  train size: 60994. test size: 15026, cols: 318 \n",
      "folder 13 size train: 60994 size cv: 15026 AUC (fold 2/5): 0.836251\n",
      "folder 13  train size: 60788. test size: 15232, cols: 318 \n",
      "folder 13 size train: 60788 size cv: 15232 AUC (fold 3/5): 0.823476\n",
      "folder 13  train size: 60676. test size: 15344, cols: 318 \n",
      "folder 13 size train: 60676 size cv: 15344 AUC (fold 4/5): 0.828970\n",
      "folder 13  train size: 60801. test size: 15219, cols: 318 \n",
      "folder 13 size train: 60801 size cv: 15219 AUC (fold 5/5): 0.837090\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 14  train size: 60941. test size: 15079, cols: 318 \n",
      "folder 14 size train: 60941 size cv: 15079 AUC (fold 1/5): 0.832670\n",
      "folder 14  train size: 60631. test size: 15389, cols: 318 \n",
      "folder 14 size train: 60631 size cv: 15389 AUC (fold 2/5): 0.838833\n",
      "folder 14  train size: 60718. test size: 15302, cols: 318 \n",
      "folder 14 size train: 60718 size cv: 15302 AUC (fold 3/5): 0.821421\n",
      "folder 14  train size: 60897. test size: 15123, cols: 318 \n",
      "folder 14 size train: 60897 size cv: 15123 AUC (fold 4/5): 0.823551\n",
      "folder 14  train size: 60893. test size: 15127, cols: 318 \n",
      "folder 14 size train: 60893 size cv: 15127 AUC (fold 5/5): 0.826554\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 15  train size: 60754. test size: 15266, cols: 318 \n",
      "folder 15 size train: 60754 size cv: 15266 AUC (fold 1/5): 0.839757\n",
      "folder 15  train size: 60813. test size: 15207, cols: 318 \n",
      "folder 15 size train: 60813 size cv: 15207 AUC (fold 2/5): 0.827492\n",
      "folder 15  train size: 60955. test size: 15065, cols: 318 \n",
      "folder 15 size train: 60955 size cv: 15065 AUC (fold 3/5): 0.822863\n",
      "folder 15  train size: 60704. test size: 15316, cols: 318 \n",
      "folder 15 size train: 60704 size cv: 15316 AUC (fold 4/5): 0.826540\n",
      "folder 15  train size: 60854. test size: 15166, cols: 318 \n",
      "folder 15 size train: 60854 size cv: 15166 AUC (fold 5/5): 0.824148\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 16  train size: 60876. test size: 15144, cols: 318 \n",
      "folder 16 size train: 60876 size cv: 15144 AUC (fold 1/5): 0.829355\n",
      "folder 16  train size: 60785. test size: 15235, cols: 318 \n",
      "folder 16 size train: 60785 size cv: 15235 AUC (fold 2/5): 0.811426\n",
      "folder 16  train size: 60817. test size: 15203, cols: 318 \n",
      "folder 16 size train: 60817 size cv: 15203 AUC (fold 3/5): 0.841778\n",
      "folder 16  train size: 60911. test size: 15109, cols: 318 \n",
      "folder 16 size train: 60911 size cv: 15109 AUC (fold 4/5): 0.829400\n",
      "folder 16  train size: 60691. test size: 15329, cols: 318 \n",
      "folder 16 size train: 60691 size cv: 15329 AUC (fold 5/5): 0.831910\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 17  train size: 60996. test size: 15024, cols: 318 \n",
      "folder 17 size train: 60996 size cv: 15024 AUC (fold 1/5): 0.820002\n",
      "folder 17  train size: 60808. test size: 15212, cols: 318 \n",
      "folder 17 size train: 60808 size cv: 15212 AUC (fold 2/5): 0.839684\n",
      "folder 17  train size: 60770. test size: 15250, cols: 318 \n",
      "folder 17 size train: 60770 size cv: 15250 AUC (fold 3/5): 0.833650\n",
      "folder 17  train size: 60767. test size: 15253, cols: 318 \n",
      "folder 17 size train: 60767 size cv: 15253 AUC (fold 4/5): 0.822681\n",
      "folder 17  train size: 60739. test size: 15281, cols: 318 \n",
      "folder 17 size train: 60739 size cv: 15281 AUC (fold 5/5): 0.825471\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 18  train size: 60781. test size: 15239, cols: 318 \n",
      "folder 18 size train: 60781 size cv: 15239 AUC (fold 1/5): 0.816601\n",
      "folder 18  train size: 60992. test size: 15028, cols: 318 \n",
      "folder 18 size train: 60992 size cv: 15028 AUC (fold 2/5): 0.825848\n",
      "folder 18  train size: 60814. test size: 15206, cols: 318 \n",
      "folder 18 size train: 60814 size cv: 15206 AUC (fold 3/5): 0.840958\n",
      "folder 18  train size: 60679. test size: 15341, cols: 318 \n",
      "folder 18 size train: 60679 size cv: 15341 AUC (fold 4/5): 0.837512\n",
      "folder 18  train size: 60814. test size: 15206, cols: 318 \n",
      "folder 18 size train: 60814 size cv: 15206 AUC (fold 5/5): 0.820636\n",
      "==============================================================================================\n",
      "starting cross validation with 5 kfolds \n",
      "folder 19  train size: 60774. test size: 15246, cols: 318 \n",
      "folder 19 size train: 60774 size cv: 15246 AUC (fold 1/5): 0.827383\n",
      "folder 19  train size: 60653. test size: 15367, cols: 318 \n",
      "folder 19 size train: 60653 size cv: 15367 AUC (fold 2/5): 0.822605\n",
      "folder 19  train size: 60863. test size: 15157, cols: 318 \n",
      "folder 19 size train: 60863 size cv: 15157 AUC (fold 3/5): 0.843452\n",
      "folder 19  train size: 60897. test size: 15123, cols: 318 \n",
      "folder 19 size train: 60897 size cv: 15123 AUC (fold 4/5): 0.814494\n",
      "folder 19  train size: 60893. test size: 15127, cols: 318 \n",
      "folder 19 size train: 60893 size cv: 15127 AUC (fold 5/5): 0.835953\n",
      "==============================================================================================\n",
      " Grand AUC: 0.828922\n",
      " printing train datasets \n",
      " making test predictions \n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "        load_data=True      \n",
    "        metafolder_train=\"data/output/train/\"\n",
    "        metafolder_test=\"data/output/test/\"        \n",
    "        input_folder=\"data/input/\"\n",
    "        feature_folder=\"data/output/features/\"\n",
    "        SEED=15\n",
    "        outset=\"lightgbm_1\" # predic of all files\n",
    "        number_of_folds=5 # repeat the CV procedure 10 times to get more precise results       \n",
    "        \n",
    "        ######### Load files ############\n",
    "\n",
    "        y=loadcolumn(input_folder+ \"train.csv\",col=370, skip=1, floats=True)\n",
    "        ids=loadcolumn(input_folder+ \"test.csv\",col=0, skip=1, floats=True)\n",
    "        idstrain=loadcolumn(input_folder+ \"train.csv\",col=0, skip=1, floats=True)\n",
    "        keepfold=[0 for k in range(len(y))]\n",
    "        \n",
    "        if load_data:\n",
    "            X,X_test=all_load_vecorizerr(input_folder+'train.csv',input_folder+'test.csv') \n",
    "            printfile(X,\"Xvector.pkl\")  \n",
    "            printfile(X_test,\"Xtestvector.pkl\")                               \n",
    "            X=load_datas(\"Xvector.pkl\").toarray()\n",
    "            X_test=load_datas(\"Xtestvector.pkl\").toarray()\n",
    "\n",
    "\n",
    "        tsn_features=(np.loadtxt(feature_folder+ \"tsne_feats.csv\", delimiter=\",\", skiprows=1, usecols=[1,2]))\n",
    "        \n",
    "        tsn_features_train=tsn_features[:X.shape[0]]\n",
    "        tsn_features_test=tsn_features[X.shape[0]:tsn_features.shape[0]]     \n",
    "        \n",
    "        print(tsn_features_train.shape)\n",
    "        print(tsn_features_test.shape)\n",
    "\n",
    "        X=np.column_stack((X,tsn_features_train))     \n",
    "        X_test=np.column_stack((X_test,tsn_features_test)) \n",
    "\n",
    "        print(X.shape)       \n",
    "        print(X_test.shape)\n",
    "\n",
    "        kmeans_feats=(np.loadtxt(feature_folder+\"kmeans_feats.csv\", delimiter=\",\", skiprows=1, usecols=[1,2,3,4,5,6,7,8,9]))\n",
    "        \n",
    "        kmeans_feats_train=kmeans_feats[:X.shape[0]]\n",
    "        kmeans_feats_test=kmeans_feats[X.shape[0]:tsn_features.shape[0]]     \n",
    "        \n",
    "        print(kmeans_feats_train.shape)\n",
    "        print(kmeans_feats_test.shape)\n",
    "\n",
    "        X=np.column_stack((X,kmeans_feats_train))     \n",
    "        X_test=np.column_stack((X_test,kmeans_feats_test)) \n",
    "\n",
    "        print(X.shape)\n",
    "        print(X_test.shape)      \n",
    "\n",
    "\n",
    "        #model to use\n",
    "                                                           \n",
    "        model=lgbm.LGBMClassifier(n_estimators = 1000, num_leaves = 35, max_depth = 5, learning_rate = 0.001,\n",
    "                                  objective = 'binary', min_child_weight = 1, min_child_samples = 30,\n",
    "                                  subsample = 0.9, colsample_bytree = 0.45, random_state = 1) \n",
    "        #Create Arrays for meta\n",
    "        train_stacker=[ 0.0  for k in range (0,(X.shape[0])) ]\n",
    "        test_stacker=[0.0  for k in range (0,(X_test.shape[0]))]\n",
    "        \n",
    "        # CHECK EVerything in five..it could be more efficient     \n",
    "        \n",
    "        #create target variable        \n",
    "        print(\"kfolder\")\n",
    "        \n",
    "        #load the 20-fold ids.\n",
    "        kfolders=load_ids(input_folder+\"5fold_20times.csv\")  \n",
    "        \n",
    "        printfile(kfolders,\"kfolder.pkl\")    \n",
    "        \n",
    "        fcount=0\n",
    "        for kfolder in kfolders:\n",
    "            mean_kapa = 0.0\n",
    "            i=0 # iterator counter\n",
    "            print(\"starting cross validation with %d kfolds \" % (number_of_folds))\n",
    "            if number_of_folds>0:\n",
    "                for train_index, test_index in kfolder:\n",
    "                    # creaning and validation sets\n",
    "                    X_train, X_cv = X[train_index], X[test_index]\n",
    "                    y_train, y_cv = np.array(y)[train_index], np.array(y)[test_index]\n",
    "                           \n",
    "                    print(\"folder %d  train size: %d. test size: %d, cols: %d \" % (fcount, (X_train.shape[0]) ,(X_cv.shape[0]) ,(X_train.shape[1]) ))\n",
    "    \n",
    "                    \n",
    "                    preds=bagged_set(X_train,y_train,model, SEED, 3, X_cv, update_seed=True)        \n",
    "                    # compute Loglikelihood metric for this CV fold\n",
    "                    #scalepreds(preds)     \n",
    "                    kapa = roc_auc_score(y_cv,preds)\n",
    "                    print(\"folder %d size train: %d size cv: %d AUC (fold %d/%d): %f\" % (fcount,(X_train.shape[0]), (X_cv.shape[0]), i + 1, number_of_folds, kapa))\n",
    "                    mean_kapa += kapa\n",
    "                    #save the results\n",
    "                    no=0\n",
    "                    for real_index in test_index:\n",
    "                             train_stacker[real_index]+=(preds[no])\n",
    "                             keepfold[real_index]=i\n",
    "                             no+=1\n",
    "                    i+=1\n",
    "            fcount+=1\n",
    "            print(\"==============================================================================================\")\n",
    "        for u in range(0,len(train_stacker)):\n",
    "            train_stacker[u]/=float(len(kfolders))\n",
    "        grand_auc=roc_auc_score(y, train_stacker)\n",
    "        print(\" Grand AUC: %f\" % (grand_auc) )\n",
    "        if (number_of_folds)>0:\n",
    "            mean_kapa/=number_of_folds\n",
    "            print(\" printing train datasets \")\n",
    "            printfilcsve(np.column_stack((np.array(idstrain),np.array(train_stacker))), metafolder_train+ outset  + \".train.csv\",\"ID,TARGET\")  \n",
    " \n",
    "        print(\" making test predictions \")        \n",
    "        preds=bagged_set(X, y,model, SEED, 5, X_test, update_seed=True) \n",
    "         \n",
    "        for pr in range (0,len(preds)):            \n",
    "                    test_stacker[pr]=(preds[pr]) \n",
    "    \n",
    "        preds=np.array(preds)\n",
    "        printfilcsve(np.column_stack((np.array(ids),np.array(test_stacker))),  metafolder_test+ outset  + \".test.csv\",\"ID,TARGET\")                \n",
    "\n",
    "if __name__==\"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gFLYKiKHqiUZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMwJq19rkJE2vxslHs97oQO",
   "collapsed_sections": [],
   "name": "marios.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
